<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[ALEX BEVILACQUA]]></title>
    <link href="http://www.alexbevi.com/atom.xml" rel="self"/>
    <link href="http://www.alexbevi.com/"/>
    <updated>2020-03-30T06:56:14-04:00</updated>
    <id>http://www.alexbevi.com/</id>
    <author>
        <name><![CDATA[Alex Bevilacqua]]></name>
        <email><![CDATA[alex@alexbevi.com]]></email>
    </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[Working around MongoDB Stitch's "max async work queue" limit]]></title>
        <link href="http://www.alexbevi.com/blog/2020/03/30/working-around-mongodb-stitchs-max-async-work-queue-limit/"/>
        <updated>2020-03-30T05:19:32-04:00</updated>
        <id>http://www.alexbevi.com/blog/2020/03/30/working-around-mongodb-stitchs-max-async-work-queue-limit</id>
        <content type="html"><![CDATA[<p><a href="https://www.mongodb.com/cloud/stitch">MongoDB Stitch</a> is a great way to build apps quickly with your data that&rsquo;s already managed by <a href="https://www.mongodb.com/cloud/atlas">MongoDB Atlas</a>. Though these services empower you to focus on development without having worry about infrastructure, being a managed service there are occasionally limitations imposed by the vendor.</p>

<p>This article summarizes why this limit exists, as well as how to adapt your <a href="https://docs.mongodb.com/stitch/functions/">MongoDB Stitch Functions</a> to work around it.</p>

<!-- more -->


<p>The following is an <a href="https://docs.mongodb.com/stitch/services/http">HTTP Service</a> I&rsquo;ve written that has an <a href="https://docs.mongodb.com/stitch/services/http/">incoming webhook</a>. When this webhook is called a MongoDB Stitch Function is run which inserts a number of documents. The number to insert is defined by the <code>maxItems</code> <a href="https://en.wikipedia.org/wiki/Query_string"><em>query parameter</em></a> of the <a href="https://docs.mongodb.com/stitch/services/http/#request-payload">request payload</a> provided to the incoming webhook.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// MongoDB Stitch Function code for the Incoming Webhook</span>
</span><span class='line'><span class="nx">exports</span> <span class="o">=</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">payload</span><span class="p">,</span> <span class="nx">response</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">maxItems</span> <span class="o">=</span> <span class="nb">parseInt</span><span class="p">(</span><span class="nx">payload</span><span class="p">.</span><span class="nx">query</span><span class="p">.</span><span class="nx">maxItems</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">CLUSTER</span>    <span class="o">=</span> <span class="s1">&#39;mongodb-atlas&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">DB</span>         <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">COLLECTION</span> <span class="o">=</span> <span class="s1">&#39;web_worker_queue_failures&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">collection</span> <span class="o">=</span> <span class="nx">context</span><span class="p">.</span><span class="nx">services</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="nx">CLUSTER</span><span class="p">).</span><span class="nx">db</span><span class="p">(</span><span class="nx">DB</span><span class="p">).</span><span class="nx">collection</span><span class="p">(</span><span class="nx">COLLECTION</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">items</span> <span class="o">=</span> <span class="p">[];</span>
</span><span class='line'>  <span class="k">for</span><span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">maxItems</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">items</span><span class="p">.</span><span class="nx">push</span><span class="p">({</span> <span class="nx">a</span><span class="o">:</span> <span class="nx">i</span> <span class="p">});</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">results</span> <span class="o">=</span> <span class="p">[];</span>
</span><span class='line'>  <span class="nx">items</span><span class="p">.</span><span class="nx">forEach</span><span class="p">((</span><span class="nx">item</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">collection</span><span class="p">.</span><span class="nx">insertOne</span><span class="p">(</span><span class="nx">item</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">res</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">results</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">res</span><span class="p">);</span>
</span><span class='line'>    <span class="p">},</span> <span class="nx">error</span> <span class="o">=&gt;</span> <span class="p">{</span>
</span><span class='line'>      <span class="nx">results</span><span class="p">.</span><span class="nx">push</span><span class="p">({</span> <span class="nx">error</span><span class="o">:</span> <span class="nx">error</span> <span class="p">});</span>
</span><span class='line'>      <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">error</span><span class="p">);</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>  <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span> <span class="s2">&quot;Processed&quot;</span><span class="o">:</span> <span class="nx">items</span><span class="p">.</span><span class="nx">length</span> <span class="p">};</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<p>When the webhook is executed, the number of items processed is returned. In the following example we&rsquo;ll specify that we want 900 items to be inserted:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -w <span class="s2">&quot;\nTotal Time: %{time_total}s\n&quot;</span> <span class="se">\</span>
</span><span class='line'>     -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{}&#39;</span> <span class="se">\</span>
</span><span class='line'>     https://webhooks.mongodb-stitch.com/api/client/v2.0/app/cluster0-app0-abcde/service/WebWorkerFailureTest/incoming_webhook/webhook0?maxItems<span class="o">=</span>900
</span><span class='line'><span class="o">{</span><span class="s2">&quot;Processed&quot;</span>:<span class="o">{</span><span class="s2">&quot;$numberInt&quot;</span>:<span class="s2">&quot;900&quot;</span><span class="o">}}</span>
</span><span class='line'>Total Time: 1.729469s
</span></code></pre></td></tr></table></div></figure>


<p>Based on the output returned from the webhook, 900 items were inserted. Next we&rsquo;ll try with 9000 items:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -w <span class="s2">&quot;\nTotal Time: %{time_total}s\n&quot;</span> <span class="se">\</span>
</span><span class='line'>     -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{}&#39;</span> <span class="se">\</span>
</span><span class='line'>     https://webhooks.mongodb-stitch.com/api/client/v2.0/app/cluster0-app0-abcde/service/WebWorkerFailureTest/incoming_webhook/webhook0?maxItems<span class="o">=</span>9000
</span><span class='line'><span class="o">{</span><span class="s2">&quot;error&quot;</span>:<span class="s2">&quot;exceeded max async work queue size of 1000&quot;</span>,<span class="s2">&quot;error_code&quot;</span>:<span class="s2">&quot;FunctionExecutionError&quot;</span>,<span class="s2">&quot;link&quot;</span>:<span class="s2">&quot;https://stitch.mongodb.com/groups/13c415400000000000000000/apps/13c415400000000000000000/logs?co_id=13c415400000000000000000&quot;</span><span class="o">}</span>
</span><span class='line'>Total Time: 0.371383s
</span></code></pre></td></tr></table></div></figure>


<p>The reason this error is thrown has to do with how the MongoDB Stitch platform handles async request execution within functions using an internal work queue. Operations such as <a href="https://docs.mongodb.com/stitch/mongodb/actions/collection.insertOne/"><code>insertOne</code></a> within a function are leveraging the MongoDB Stitch JavaScript SDK&rsquo;s <a href="https://docs.mongodb.com/stitch-sdks/js/4/interfaces/remotemongocollection.html#insertone"><code>insertOne</code></a> method, which returns a <a href="https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise">Promise</a><a href="https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise">https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise</a>). To ensure these promises don&rsquo;t queue infinitely waiting to be resolved, MongoDB Stitch will arbitrarily limit the number that can be enqueued, and if this limit is exceeded queuing stops and the exception is raised.</p>

<p>To work around this limit we will adapt our earlier code to instead throttle our work loop to ensure batches of 1000 or less are processed before more work is attempted.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="kr">const</span> <span class="nx">processWork</span> <span class="o">=</span> <span class="nx">async</span> <span class="kd">function</span><span class="p">(</span><span class="nx">items</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">CLUSTER</span>    <span class="o">=</span> <span class="s1">&#39;mongodb-atlas&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">DB</span>         <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">COLLECTION</span> <span class="o">=</span> <span class="s1">&#39;web_worker_queue_failures&#39;</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">collection</span> <span class="o">=</span> <span class="nx">context</span><span class="p">.</span><span class="nx">services</span><span class="p">.</span><span class="nx">get</span><span class="p">(</span><span class="nx">CLUSTER</span><span class="p">).</span><span class="nx">db</span><span class="p">(</span><span class="nx">DB</span><span class="p">).</span><span class="nx">collection</span><span class="p">(</span><span class="nx">COLLECTION</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>
</span><span class='line'>  <span class="kr">const</span> <span class="nx">totalItems</span> <span class="o">=</span> <span class="nx">items</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">for</span> <span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">totalItems</span><span class="p">;</span> <span class="nx">i</span> <span class="o">+=</span> <span class="nx">BATCH_SIZE</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="kr">const</span> <span class="nx">requests</span> <span class="o">=</span> <span class="nx">items</span><span class="p">.</span><span class="nx">slice</span><span class="p">(</span><span class="nx">i</span><span class="p">,</span> <span class="nx">i</span> <span class="o">+</span> <span class="nx">BATCH_SIZE</span><span class="p">).</span><span class="nx">map</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">item</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>      <span class="k">return</span> <span class="nx">collection</span><span class="p">.</span><span class="nx">insertOne</span><span class="p">(</span><span class="nx">item</span><span class="p">).</span><span class="k">catch</span><span class="p">(</span><span class="nx">e</span> <span class="o">=&gt;</span> <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">e</span><span class="p">));</span>
</span><span class='line'>    <span class="p">});</span>
</span><span class='line'>
</span><span class='line'>    <span class="nx">await</span> <span class="nx">Promise</span><span class="p">.</span><span class="nx">all</span><span class="p">(</span><span class="nx">requests</span><span class="p">).</span><span class="k">catch</span><span class="p">(</span><span class="nx">e</span> <span class="o">=&gt;</span> <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="err">`</span><span class="nx">Errors</span> <span class="k">in</span> <span class="nx">batch</span> <span class="nx">$</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">:</span> <span class="nx">$</span><span class="p">{</span><span class="nx">e</span><span class="p">}</span><span class="err">`</span><span class="p">));</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// MongoDB Stitch Function code for the Incoming Webhook</span>
</span><span class='line'><span class="nx">exports</span> <span class="o">=</span> <span class="kd">function</span> <span class="p">(</span><span class="nx">payload</span><span class="p">,</span> <span class="nx">response</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">maxItems</span> <span class="o">=</span> <span class="nb">parseInt</span><span class="p">(</span><span class="nx">payload</span><span class="p">.</span><span class="nx">query</span><span class="p">.</span><span class="nx">maxItems</span><span class="p">);</span>
</span><span class='line'>  <span class="kd">let</span> <span class="nx">items</span> <span class="o">=</span> <span class="p">[];</span>
</span><span class='line'>  <span class="k">for</span><span class="p">(</span><span class="kd">let</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">maxItems</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class='line'>    <span class="nx">items</span><span class="p">.</span><span class="nx">push</span><span class="p">({</span> <span class="nx">a</span><span class="o">:</span> <span class="nx">i</span> <span class="p">});</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="nx">processWork</span><span class="p">(</span><span class="nx">items</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">return</span> <span class="p">{</span> <span class="s2">&quot;Processed&quot;</span><span class="o">:</span> <span class="nx">items</span><span class="p">.</span><span class="nx">length</span> <span class="p">};</span>
</span><span class='line'><span class="p">};</span>
</span></code></pre></td></tr></table></div></figure>


<p>The number of items to process (based on <code>maxItems</code> again) will now be broken up into batches (<code>BATCH_SIZE</code>) and using <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all"><code>Promise.all()</code></a> all the operations in a batch will be fulfilled before another batch is processed.</p>

<p>This method allows the workload to be artificially throttled to allow <code>maxItems</code> operations to be executed. Let&rsquo;s try running our webhook again for 9000 items:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -w <span class="s2">&quot;\nTotal Time: %{time_total}s\n&quot;</span> <span class="se">\</span>
</span><span class='line'>     -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{}&#39;</span> <span class="se">\</span>
</span><span class='line'>     https://webhooks.mongodb-stitch.com/api/client/v2.0/app/cluster0-app0-abcde/service/WebWorkerFailureTest/incoming_webhook/webhook0?maxItems<span class="o">=</span>9000
</span><span class='line'><span class="o">{</span><span class="s2">&quot;Processed&quot;</span>:<span class="o">{</span><span class="s2">&quot;$numberInt&quot;</span>:<span class="s2">&quot;9000&quot;</span><span class="o">}}</span>
</span><span class='line'>Total Time: 13.935162s
</span></code></pre></td></tr></table></div></figure>


<p>Note that although this strategy will work with an array of items (<code>maxItems</code>) of any size, MongoDB Stitch Functions still have runtime limit of 90 seconds (see <a href="https://docs.mongodb.com/stitch/functions/#constraints">&ldquo;Constraints&rdquo;</a>) which cannot be circumvented. If we try running the function for 90000 items, if the function runs for > 90 seconds execution will be terminated:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>curl -w <span class="s2">&quot;\nTotal Time: %{time_total}s\n&quot;</span> <span class="se">\</span>
</span><span class='line'>     -H <span class="s2">&quot;Content-Type: application/json&quot;</span> -d <span class="s1">&#39;{}&#39;</span> <span class="se">\</span>
</span><span class='line'>     https://webhooks.mongodb-stitch.com/api/client/v2.0/app/cluster0-app0-abcde/service/WebWorkerFailureTest/incoming_webhook/webhook0?maxItems<span class="o">=</span>90000
</span><span class='line'><span class="o">{</span><span class="s2">&quot;error&quot;</span>:<span class="s2">&quot;execution time limit exceeded&quot;</span>,<span class="s2">&quot;error_code&quot;</span>:<span class="s2">&quot;ExecutionTimeLimitExceeded&quot;</span>,<span class="s2">&quot;link&quot;</span>:<span class="s2">&quot;https://stitch.mongodb.com/groups/13c415400000000000000000/apps/13c415400000000000000000/logs?co_id=13c415400000000000000000&quot;</span><span class="o">}</span>
</span><span class='line'>Total Time: 90.311827s
</span></code></pre></td></tr></table></div></figure>


<p>Happy Coding!</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Identifying and Reclaiming Disk Space in MongoDB]]></title>
        <link href="http://www.alexbevi.com/blog/2020/03/15/identifying-and-reclaiming-disk-space-in-mongodb/"/>
        <updated>2020-03-15T16:23:38-04:00</updated>
        <id>http://www.alexbevi.com/blog/2020/03/15/identifying-and-reclaiming-disk-space-in-mongodb</id>
        <content type="html"><![CDATA[<p>A common question when it comes to MongoDB and the (default) storage engine (<a href="https://docs.mongodb.com/manual/core/wiredtiger/">WiredTiger</a>) is &ldquo;Why is it after I removed a bunch of documents my free space didn&rsquo;t increase&rdquo;?</p>

<p>The WiredTiger storage engine maintains lists of empty records in data files as it deletes documents. This space can be reused by WiredTiger, but will not be returned to the operating system unless under very specific circumstances.</p>

<p>The amount of empty space available for reuse by WiredTiger is reflected in the output of <a href="https://docs.mongodb.com/manual/reference/method/db.collection.stats/#db.collection.stats"><code>db.collection.stats()</code></a> under the heading <code>wiredTiger.block-manager.file bytes available for reuse</code>.</p>

<p>To allow the WiredTiger storage engine to release this empty space to the operating system, you can de-fragment your data file. This can be achieved using the <a href="https://docs.mongodb.com/manual/reference/command/compact/#dbcmd.compact"><code>compact</code> command</a>.</p>

<p>As the <code>db.collection.stats()</code> command must be run one <a href="https://docs.mongodb.com/manual/reference/glossary/#term-collection">collection</a> at a time I&rsquo;ve written the following script to enhance this functionality as follows:</p>

<ul>
<li>scan all <a href="https://docs.mongodb.com/manual/reference/glossary/#term-namespace">namespaces</a> (<a href="https://docs.mongodb.com/manual/reference/glossary/#term-database">databases</a> + collections)</li>
<li>include index space details</li>
<li>support for sharded collections</li>
<li>output to CSV</li>
</ul>


<!-- MORE -->


<p><noscript><pre>/<em>
* Print storage details for all collections and indexes.
* Supports sharded clusters
*
* @author <a href="&#109;&#x61;&#105;&#x6c;&#116;&#111;&#x3a;&#97;&#x6c;&#101;&#120;&#x2e;&#x62;&#x65;&#x76;&#x69;&#x6c;&#x61;&#x63;&#113;&#117;&#97;&#64;&#109;&#x6f;&#x6e;&#103;&#111;&#100;&#x62;&#x2e;&#99;&#111;&#x6d;">&#x61;&#108;&#x65;&#120;&#x2e;&#98;&#101;&#x76;&#x69;&#x6c;&#97;&#x63;&#113;&#117;&#97;&#64;&#109;&#x6f;&#110;&#103;&#x6f;&#100;&#98;&#x2e;&#99;&#111;&#109;</a>
* @updated 2020-02-25
</em>/</p>

<p>var fmt = function (bytes) {
    var sizes = [&#39;Bytes&#39;, &#39;KB&#39;, &#39;MB&#39;, &#39;GB&#39;, &#39;TB&#39;];
    if (bytes == 0) return &#39;0 Byte&#39;;
    var i = parseInt(Math.floor(Math.log(bytes) / Math.log(1024)));
    return Math.round(bytes / Math.pow(1024, i), 2) + &#39; &#39; + sizes[i];
}</p>

<p>var getDetail = function (label, stats) {
    var detail = {
        name: label,
        size: stats.size,
        storageSize: stats.storageSize,
        reusableSpace: stats.wiredTiger[&quot;block-manager&quot;][&quot;file bytes available for reuse&quot;],
        indexSpace: stats.totalIndexSize,
        indexReusable: 0,
    };</p>

<pre><code>var indexKeys = Object.keys(stats.indexDetails);
for (var i = 0; i &amp;lt; indexKeys.length; i++) {
    detail.indexReusable += stats.indexDetails[indexKeys[i]][&amp;quot;block-manager&amp;quot;][&amp;quot;file bytes available for reuse&amp;quot;];
}

return detail;
</code></pre>

<p>}</p>

<p>var dbSizeReport = function (dbname) {
    var results = []
    db.getSiblingDB(dbname).getCollectionNames().forEach(function &copy; {
        var coll = db.getSiblingDB(dbname).getCollection&copy;;
        var s = coll.stats({
            indexDetails: true
        });
        if (s.hasOwnProperty(&quot;sharded&quot;) &amp;&amp; s.sharded) {
            var shards = Object.keys(s.shards);
            for (var i = 0; i &lt; shards.length; i++) {
                var shard = shards[i];
                var shardStat = s.shards[shard];
                results.push(getDetail(s.ns + &quot; (&quot; + shard + &quot;)&quot;, shardStat));
            }
        } else {
            results.push(getDetail(s.ns, s));
        }
    });</p>

<pre><code>var totals = [0, 0, 0, 0, 0];
print([&amp;quot;Namespace&amp;quot;, &amp;quot;Uncompressed&amp;quot;, &amp;quot;Compressed&amp;quot;, &amp;quot;Reusable from Collections&amp;quot;, &amp;quot;Indexes&amp;quot;, &amp;quot;Reusable from Indexes&amp;quot;].join(&amp;quot;,&amp;quot;))
for (var i = 0; i &amp;lt; results.length; i++) {
    var row = results[i];
    print([row.name, fmt(row.size), fmt(row.storageSize), fmt(row.reusableSpace), fmt(row.indexSpace), fmt(row.indexReusable)].join(&amp;quot;,&amp;quot;))
    totals[0] += row.size;
    totals[1] += row.storageSize;
    totals[2] += row.reusableSpace;
    totals[3] += row.indexSpace;
    totals[4] += row.indexReusable;
}

print([&amp;quot;Total&amp;quot;, fmt(totals[0]), fmt(totals[1]), fmt(totals[2]), fmt(totals[3]), fmt(totals[4])].join(&amp;quot;,&amp;quot;));
</code></pre>

<p>}</p>

<p>db.getMongo().getDBNames().forEach(function (dbname) {
    print(&quot;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&quot;)
    print(dbname);
    print(&quot;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&quot;)
    dbSizeReport(dbname);
});
</pre></noscript><script src="https://gist.github.com/alexbevi/d89d8ce406e7fcea9f0915b7a7580c28.js"> </script></p>

<p>Running this script from a <code>mongo</code> shell will produce output similar to the following:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>---------------------
</span><span class='line'>admin
</span><span class='line'>---------------------
</span><span class='line'>Namespace,Uncompressed,Compressed,Reusable from Collections,Indexes,Reusable from Indexes
</span><span class='line'>admin.system.keys (config),255 Bytes,36 KB,16 KB,36 KB,16 KB
</span><span class='line'>admin.system.version (config),59 Bytes,20 KB,0 Byte,20 KB,0 Byte
</span><span class='line'>Total,314 Bytes,56 KB,16 KB,56 KB,16 KB
</span><span class='line'>---------------------
</span><span class='line'>config
</span><span class='line'>---------------------
</span><span class='line'>Namespace,Uncompressed,Compressed,Reusable from Collections,Indexes,Reusable from Indexes
</span><span class='line'>config.actionlog (config),32 KB,40 KB,16 KB,40 KB,16 KB
</span><span class='line'>config.changelog (config),346 KB,132 KB,52 KB,96 KB,44 KB
</span><span class='line'>config.chunks (config),57 KB,52 KB,24 KB,144 KB,64 KB
</span><span class='line'>config.collections (config),431 Bytes,36 KB,16 KB,36 KB,16 KB
</span><span class='line'>config.databases (config),108 Bytes,20 KB,0 Byte,20 KB,0 Byte
</span><span class='line'>config.lockpings (config),3 KB,36 KB,16 KB,72 KB,32 KB
</span><span class='line'>config.locks (config),771 Bytes,36 KB,16 KB,108 KB,48 KB
</span><span class='line'>config.migrations (config),0 Byte,24 KB,16 KB,48 KB,32 KB
</span><span class='line'>config.mongos (config),342 Bytes,36 KB,16 KB,20 KB,0 Byte
</span><span class='line'>config.settings (config),39 Bytes,20 KB,0 Byte,20 KB,0 Byte
</span><span class='line'>config.shards (config),297 Bytes,20 KB,0 Byte,44 KB,4 KB
</span><span class='line'>config.system.sessions (shard01),99 Bytes,36 KB,16 KB,60 KB,20 KB
</span><span class='line'>config.tags (config),0 Byte,4 KB,0 Byte,24 KB,4 KB
</span><span class='line'>config.transactions (config),0 Byte,24 KB,16 KB,12 KB,4 KB
</span><span class='line'>config.version (config),83 Bytes,20 KB,0 Byte,20 KB,0 Byte
</span><span class='line'>Total,441 KB,536 KB,204 KB,764 KB,284 KB
</span><span class='line'>---------------------
</span><span class='line'>test
</span><span class='line'>---------------------
</span><span class='line'>Namespace,Uncompressed,Compressed,Reusable from Collections,Indexes,Reusable from Indexes
</span><span class='line'>test.test1 (shard01),37 MB,37 MB,27 MB,26 MB,16 MB
</span><span class='line'>test.test1 (shard02),37 MB,8 MB,52 KB,5 MB,2 MB
</span><span class='line'>test.test1 (shard03),38 MB,8 MB,56 KB,5 MB,2 MB
</span><span class='line'>test.ups_test (shard01),0 Byte,24 KB,16 KB,72 KB,48 KB
</span><span class='line'>Total,112 MB,54 MB,27 MB,36 MB,19 MB</span></code></pre></td></tr></table></div></figure>


<p>This output can then being imported into your favourite spreadsheet for further manipulation.</p>

<p>Based on this sample output, the <code>test.test1</code> collection on <code>shard01</code> could reclaim approximately 27MB if <code>compact</code>ed. Note that the amount of space reclaimed will not necessarily be exactly what is reported here, but is generally a good guideline as to how much space may be reclaimed.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[MongoDB Initial Sync Progress Monitoring]]></title>
        <link href="http://www.alexbevi.com/blog/2020/02/13/mongodb-initial-sync-progress-monitoring/"/>
        <updated>2020-02-13T12:34:49-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/02/13/mongodb-initial-sync-progress-monitoring</id>
        <content type="html"><![CDATA[<p>Sometimes our replica set members fall off the <a href="https://docs.mongodb.com/manual/core/replica-set-oplog/">oplog</a> and the node needs to be resynced. When this happens, an <a href="https://docs.mongodb.com/manual/core/replica-set-sync/#initial-sync">Initial Sync</a> is required, which does the following:</p>

<ol>
<li>Clones all databases except the local database. To clone, the <code>mongod</code> scans every collection in each source database and inserts all data into its own copies of these collections.</li>
<li>Applies all changes to the data set. Using the oplog from the source, the <code>mongod</code> updates its data set to reflect the current state of the replica set.</li>
</ol>


<p>When the initial sync finishes, the member transitions from <a href="https://docs.mongodb.com/manual/reference/replica-states/#replstate.STARTUP2"><code>STARTUP2</code></a> to <a href="https://docs.mongodb.com/manual/reference/replica-states/#replstate.SECONDARY"><code>SECONDARY</code></a>.</p>

<p>Some common questions when performing an initial sync of a <a href="https://docs.mongodb.com/manual/core/replica-set-members/">Replica Set Member</a> are:</p>

<ul>
<li>How do I know if the sync is progressing?</li>
<li>How long will this take to complete?</li>
</ul>


<!-- MORE -->


<p>Determining if the sync is progressing can be done by either checking the size of the <a href="https://docs.mongodb.com/manual/reference/configuration-options/#storage.dbPath"><code>dbPath</code></a> of the syncing node or by running the <a href="https://docs.mongodb.com/manual/reference/command/replSetGetStatus/"><code>db.adminCommand({ replSetGetStatus: 1, initialSync: 1 })</code></a> command while connected to the SECONDARY via the mongo shell.</p>

<p><img src="http://www.alexbevi.com/images/initsync-001.png"></p>

<p>Checking the directory size of the SECONDARY that is being initial sync'ed will provide a good approximation as to how much data still remains to be copied. Note that as the WiredTiger storage engine doesn&rsquo;t &ldquo;release&rdquo; space when documents are deleted there is a high probability that the SECONDARY will have a <em>smaller total directory size</em> than the sync source.</p>

<p>The second step (after cloning) where the oplog entries are applied will also affect the overall time required to sync from the sync source.</p>

<p>The <code>replSetGetStatus</code> command will produce a JSON document similar to the following. This document contains extensive details as to how the database/collection cloning is progressing, as well as any errors that have occurred during the process.</p>

<p><noscript><pre>{
  &quot;set&quot;: &quot;replset&quot;,
  &quot;date&quot;: ISODate(&quot;2019-12-04T05:12:52.835Z&quot;),
  &quot;myState&quot;: 5,
  &quot;term&quot;: NumberLong(3),
  &quot;syncingTo&quot;: &quot;m2.example.net:27017&quot;,
  &quot;syncSourceHost&quot;: &quot;m2.example.net:27017&quot;,
  &quot;syncSourceId&quot;: 1,
  &quot;heartbeatIntervalMillis&quot;: NumberLong(2000),
  &quot;majorityVoteCount&quot;: 2,
  &quot;writeMajorityCount&quot;: 2,
  &quot;optimes&quot;: {
    &quot;lastCommittedOpTime&quot;: {
      &quot;ts&quot;: Timestamp(0, 0),
      &quot;t&quot;: NumberLong(-1)
    },
    &quot;lastCommittedWallTime&quot;: ISODate(&quot;1970-01-01T00:00:00Z&quot;),
    &quot;appliedOpTime&quot;: {
      &quot;ts&quot;: Timestamp(0, 0),
      &quot;t&quot;: NumberLong(-1)
    },
    &quot;durableOpTime&quot;: {
      &quot;ts&quot;: Timestamp(0, 0),
      &quot;t&quot;: NumberLong(-1)
    },
    &quot;lastAppliedWallTime&quot;: ISODate(&quot;1970-01-01T00:00:00Z&quot;),
    &quot;lastDurableWallTime&quot;: ISODate(&quot;1970-01-01T00:00:00Z&quot;)
  },
  &quot;lastStableRecoveryTimestamp&quot;: Timestamp(0, 0),
  &quot;lastStableCheckpointTimestamp&quot;: Timestamp(0, 0),
  &quot;initialSyncStatus&quot;: {
    &quot;failedInitialSyncAttempts&quot;: 0,
    &quot;maxFailedInitialSyncAttempts&quot;: 10,
    &quot;initialSyncStart&quot;: ISODate(&quot;2019-12-04T05:12:35.719Z&quot;),
    &quot;initialSyncAttempts&quot;: [],
    &quot;fetchedMissingDocs&quot;: 0,
    &quot;appliedOps&quot;: 0,
    &quot;initialSyncOplogStart&quot;: Timestamp(1575436355, 1),
    &quot;databases&quot;: {
      &quot;databasesCloned&quot;: 2,
      &quot;admin&quot;: {
        &quot;collections&quot;: 4,
        &quot;clonedCollections&quot;: 4,
        &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:35.947Z&quot;),
        &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.486Z&quot;),
        &quot;elapsedMillis&quot;: 539,
        &quot;admin.system.roles&quot;: {
          &quot;documentsToCopy&quot;: 12,
          &quot;documentsCopied&quot;: 12,
          &quot;indexes&quot;: 2,
          &quot;fetchedBatches&quot;: 1,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:35.950Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.101Z&quot;),
          &quot;elapsedMillis&quot;: 151,
          &quot;receivedBatches&quot;: 1
        },
        &quot;admin.system.users&quot;: {
          &quot;documentsToCopy&quot;: 22,
          &quot;documentsCopied&quot;: 22,
          &quot;indexes&quot;: 2,
          &quot;fetchedBatches&quot;: 1,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.101Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.252Z&quot;),
          &quot;elapsedMillis&quot;: 151,
          &quot;receivedBatches&quot;: 1
        },
        &quot;admin.system.keys&quot;: {
          &quot;documentsToCopy&quot;: 2,
          &quot;documentsCopied&quot;: 2,
          &quot;indexes&quot;: 1,
          &quot;fetchedBatches&quot;: 1,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.252Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.372Z&quot;),
          &quot;elapsedMillis&quot;: 120,
          &quot;receivedBatches&quot;: 1
        },
        &quot;admin.system.version&quot;: {
          &quot;documentsToCopy&quot;: 2,
          &quot;documentsCopied&quot;: 2,
          &quot;indexes&quot;: 1,
          &quot;fetchedBatches&quot;: 1,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.372Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.486Z&quot;),
          &quot;elapsedMillis&quot;: 114,
          &quot;receivedBatches&quot;: 1
        }
      },
      &quot;config&quot;: {
        &quot;collections&quot;: 2,
        &quot;clonedCollections&quot;: 2,
        &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.486Z&quot;),
        &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.863Z&quot;),
        &quot;elapsedMillis&quot;: 377,
        &quot;config.transactions&quot;: {
          &quot;documentsToCopy&quot;: 0,
          &quot;documentsCopied&quot;: 0,
          &quot;indexes&quot;: 1,
          &quot;fetchedBatches&quot;: 0,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.487Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.645Z&quot;),
          &quot;elapsedMillis&quot;: 158,
          &quot;receivedBatches&quot;: 0
        },
        &quot;config.system.sessions&quot;: {
          &quot;documentsToCopy&quot;: 1,
          &quot;documentsCopied&quot;: 1,
          &quot;indexes&quot;: 2,
          &quot;fetchedBatches&quot;: 1,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.645Z&quot;),
          &quot;end&quot;: ISODate(&quot;2019-12-04T05:12:36.863Z&quot;),
          &quot;elapsedMillis&quot;: 218,
          &quot;receivedBatches&quot;: 1
        }
      },
      &quot;test&quot;: {
        &quot;collections&quot;: 1,
        &quot;clonedCollections&quot;: 0,
        &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.863Z&quot;),
        &quot;test.hugeindex&quot;: {
          &quot;documentsToCopy&quot;: 25000,
          &quot;documentsCopied&quot;: 9187,
          &quot;indexes&quot;: 2,
          &quot;fetchedBatches&quot;: 8,
          &quot;start&quot;: ISODate(&quot;2019-12-04T05:12:36.865Z&quot;),
          &quot;receivedBatches&quot;: 9
        }
      }
    }
  },
  &quot;members&quot;: [
    {
      &quot;<em>id&quot;: 0,
      &quot;name&quot;: &quot;m1.example.net:27017&quot;,
      &quot;ip&quot;: &quot;198.51.100.1&quot;,
      &quot;health&quot;: 1,
      &quot;state&quot;: 1,
      &quot;stateStr&quot;: &quot;PRIMARY&quot;,
      &quot;uptime&quot;: 17,
      &quot;optime&quot;: {
        &quot;ts&quot;: Timestamp(1575436355, 1),
        &quot;t&quot;: NumberLong(3)
      },
      &quot;optimeDurable&quot;: {
        &quot;ts&quot;: Timestamp(1575436355, 1),
        &quot;t&quot;: NumberLong(3)
      },
      &quot;optimeDate&quot;: ISODate(&quot;2019-12-04T05:12:35Z&quot;),
      &quot;optimeDurableDate&quot;: ISODate(&quot;2019-12-04T05:12:35Z&quot;),
      &quot;lastHeartbeat&quot;: ISODate(&quot;2019-12-04T05:12:52.216Z&quot;),
      &quot;lastHeartbeatRecv&quot;: ISODate(&quot;2019-12-04T05:12:51.485Z&quot;),
      &quot;pingMs&quot;: NumberLong(0),
      &quot;lastHeartbeatMessage&quot;: &quot;&quot;,
      &quot;syncingTo&quot;: &quot;&quot;,
      &quot;syncSourceHost&quot;: &quot;&quot;,
      &quot;syncSourceId&quot;: -1,
      &quot;infoMessage&quot;: &quot;&quot;,
      &quot;electionTime&quot;: Timestamp(1575434944, 1),
      &quot;electionDate&quot;: ISODate(&quot;2019-12-04T04:49:04Z&quot;),
      &quot;configVersion&quot;: 3
    },
    {
      &quot;</em>id&quot;: 1,
      &quot;name&quot;: &quot;m2.example.net:27017&quot;,
      &quot;ip&quot;: &quot;198.51.100.2&quot;,
      &quot;health&quot;: 1,
      &quot;state&quot;: 2,
      &quot;stateStr&quot;: &quot;SECONDARY&quot;,
      &quot;uptime&quot;: 17,
      &quot;optime&quot;: {
        &quot;ts&quot;: Timestamp(1575436355, 1),
        &quot;t&quot;: NumberLong(3)
      },
      &quot;optimeDurable&quot;: {
        &quot;ts&quot;: Timestamp(1575436355, 1),
        &quot;t&quot;: NumberLong(3)
      },
      &quot;optimeDate&quot;: ISODate(&quot;2019-12-04T05:12:35Z&quot;),
      &quot;optimeDurableDate&quot;: ISODate(&quot;2019-12-04T05:12:35Z&quot;),
      &quot;lastHeartbeat&quot;: ISODate(&quot;2019-12-04T05:12:52.216Z&quot;),
      &quot;lastHeartbeatRecv&quot;: ISODate(&quot;2019-12-04T05:12:52.728Z&quot;),
      &quot;pingMs&quot;: NumberLong(0),
      &quot;lastHeartbeatMessage&quot;: &quot;&quot;,
      &quot;syncingTo&quot;: &quot;&quot;,
      &quot;syncSourceHost&quot;: &quot;&quot;,
      &quot;syncSourceId&quot;: -1,
      &quot;infoMessage&quot;: &quot;&quot;,
      &quot;configVersion&quot;: 3
    },
    {
      &quot;_id&quot;: 2,
      &quot;name&quot;: &quot;m3.example.net:27017&quot;,
      &quot;ip&quot;: &quot;198.51.100.3&quot;,
      &quot;health&quot;: 1,
      &quot;state&quot;: 5,
      &quot;stateStr&quot;: &quot;STARTUP2&quot;,
      &quot;uptime&quot;: 71,
      &quot;optime&quot;: {
        &quot;ts&quot;: Timestamp(0,
        0),
        &quot;t&quot;: NumberLong(-1)
      },
      &quot;optimeDate&quot;: ISODate(&quot;1970-01-01T00:00:00Z&quot;),
      &quot;syncingTo&quot;: &quot;m2.example.net:27017&quot;,
      &quot;syncSourceHost&quot;: &quot;m2.example.net:27017&quot;,
      &quot;syncSourceId&quot;: 1,
      &quot;infoMessage&quot;: &quot;&quot;,
      &quot;configVersion&quot;: 3,
      &quot;self&quot;: true,
      &quot;lastHeartbeatMessage&quot;: &quot;&quot;
    }
  ],
  &quot;ok&quot;: 1
}</pre></noscript><script src="https://gist.github.com/alexbevi/d52ffd2e27068dcdcc616a5aaf814907.js"> </script></p>

<p>Depending on the number of databases and collections being sync'ed, the size of this document can be quite large and difficult to visually parse.</p>

<p>To improve this situation I&rsquo;ve created the following script.</p>

<p><noscript><pre>/<em>
* initialSyncProgress
* @author Alex Bevilacqua &lt;alex@alexbevi.com&gt;
*
* Can be run against a MongoDB 3.4+ mongod that is in STARTUP2 (intitial sync) state to gain some
* insight into how the sync is progressing. This script WILL NOT tell you how long until the sync
* is complete, but based on how the script reports progress can be used to estimate this.
*
* usage:
*   mongo &ndash;quiet &ndash;eval &quot;load(&#39;initialSyncProgress.js&#39;); initialSyncProgress();&quot;
</em>/
var printPercentage = function (position, length, type) {
  var p = Math.round((position / length) * 100, 2);
  return position + &quot;/&quot; + length + &quot; &quot; + type + &quot; (&quot; + p + &quot;%)&quot;;
}</p>

<p>var msToTime = function (duration) {
  var milliseconds = parseInt((duration % 1000) / 100),
    seconds = Math.floor((duration / 1000) % 60),
    minutes = Math.floor((duration / (1000 * 60)) % 60),
    hours = Math.floor((duration / (1000 * 60 * 60)) % 24);</p>

<p>  hours = (hours &lt; 10) ? &quot;0&quot; + hours : hours;
  minutes = (minutes &lt; 10) ? &quot;0&quot; + minutes : minutes;
  seconds = (seconds &lt; 10) ? &quot;0&quot; + seconds : seconds;</p>

<p>  return hours + &quot;:&quot; + minutes + &quot;:&quot; + seconds + &quot;.&quot; + milliseconds;
}</p>

<p>var initialSyncProgress = function () {
  var status = db.adminCommand({ replSetGetStatus: 1, initialSync: 1 });
  var dbs_cloned = status.initialSyncStatus.databases.databasesCloned;
  delete status.initialSyncStatus.databases.databasesCloned;
  var dbs = Object.keys(status.initialSyncStatus.databases);
  var dbs_total = dbs.length;</p>

<p>  // total time elapsed syncing databases
  var elapsedMillis = 0;</p>

<p>  // status message based on the position within the currently
  // cloning database (collections cloned of collections total)
  var currentlyCloningStatus = &quot;&quot;;</p>

<p>  for (var i = 0; i &lt; dbs_total; i++) {
    var d = status.initialSyncStatus.databases[dbs[i]];
    // if the counts aren&#39;t the same either it&#39;s the database that&#39;s in progress or
    // hasn&#39;t started cloning yet
    if (d.clonedCollections &lt; d.collections) {
      currentlyCloningStatus = &quot;Cloning database &quot; + dbs[i];
      currentlyCloningStatus += &quot; - cloned &quot; + printPercentage(d.clonedCollections, d.collections, &quot;collections&quot;);
      var collectionKeys = Object.keys(d);
      for (var j = 0; j &lt; collectionKeys.length; j++) {
        var c = d[collectionKeys[j]];
        if (c.hasOwnProperty(&quot;documentsToCopy&quot;) &amp;&amp; (c.documentsCopied &lt; c.documentsToCopy)) {
          currentlyCloningStatus += &quot;\nCloning collection &quot; + collectionKeys[j] + &quot; &quot; + printPercentage(c.documentsCopied, c.documentsToCopy, &quot;documents&quot;);
        }
      }
    }
    // only add time if there&#39;s time to record
    if (d.hasOwnProperty(&quot;elapsedMillis&quot;)) {
      elapsedMillis += d.elapsedMillis;
    }
  }
  print(&quot;===================&quot;)
  print(&quot;Initial Sync Status&quot;)
  print(&quot;===================&quot;)
  var now = new Date();
  var started = status.initialSyncStatus.initialSyncStart;
  print(&quot;Cloning started at &quot; + started + &quot; (&quot; + msToTime(now - started) + &quot; ago)&quot;);
  var members = status.members;
  for (var i = 0; i &lt; members.length; i++) {
    if (members[i].stateStr == &quot;PRIMARY&quot;) {
      var optime = members[i].optimeDate
      var me = new Date(status.initialSyncStatus.initialSyncOplogStart.getTime() * 1000);
      print(&quot;Currently &quot; + msToTime(optime - me) + &quot; behind the PRIMARY (based on optimes)&quot;);
    }
  }
  if (status.initialSyncStatus.hasOwnProperty(&quot;initialSyncAttempts&quot;) &amp;&amp; status.initialSyncStatus.initialSyncAttempts.length &gt; 0) {
    var failures = status.initialSyncStatus.initialSyncAttempts.length;
    print(&quot;Cloning has already failed &quot; + failures + &quot; time(s) &hellip;&quot;);
    print(&quot;Last Failure: &quot; + status.initialSyncStatus.initialSyncAttempts[failures - 1].status);
  }
  print(&quot;Copying databases for &quot; + msToTime(elapsedMillis) + &quot;. Note this updates AFTER a collection has been cloned.&quot;);
  print(&quot;Cloned &quot; + printPercentage(dbs_cloned, dbs_total, &quot;databases&quot;));
  print(currentlyCloningStatus);
}
</pre></noscript><script src="https://gist.github.com/alexbevi/422890f191f4bcb82c06fbb621c69331.js"> </script></p>

<p>By running this against the SECONDARY from the mongo shell, a more concise representation of the <code>initialSyncStatus</code> document is produced:</p>

<p><img src="http://www.alexbevi.com/images/initsync-002.png"></p>

<p>The script will also let you know if there have been any sync failures recorded, as well as what the last failure was.</p>

<p><img src="http://www.alexbevi.com/images/initsync-003.png"></p>

<p>Hopefully you&rsquo;ll find this useful when the time comes to resync one of your nodes.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[What is MongoDB FTDC (aka. diagnostic.data)]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/26/what-is-mongodb-ftdc-aka-diagnostic-dot-data/"/>
        <updated>2020-01-26T18:14:50-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/26/what-is-mongodb-ftdc-aka-diagnostic-dot-data</id>
        <content type="html"><![CDATA[<p><a href="https://docs.mongodb.com/manual/administration/analyzing-mongodb-performance/#full-time-diagnostic-data-capture">Full Time Diagnostic Data Capture (FTDC)</a> was introduced in MongoDB 3.2 (via <a href="https://jira.mongodb.org/browse/SERVER-19585">SERVER-19585</a>), to incrementally collect the results of certain diagnostic commands to assist MongoDB support with troubleshooting issues.</p>

<p>On log rotation or startup, a <code>mongod</code> or <code>mongos</code> will collect and log:</p>

<ul>
<li><a href="https://docs.mongodb.com/manual/reference/command/getCmdLineOpts/"><code>getCmdLineOpts</code></a>: <code>db.adminCommand({getCmdLineOpts: true})</code></li>
<li><a href="https://docs.mongodb.com/manual/reference/command/buildInfo/"><code>buildInfo</code></a>: <code>db.adminCommand({buildInfo: true})</code></li>
<li><a href="https://docs.mongodb.com/manual/reference/command/hostInfo/"><code>hostInfo</code></a>: <code>db.adminCommand({hostInfo: true})</code></li>
</ul>


<p>As configured by <a href="https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionPeriodMillis"><code>diagnosticDataCollectionPeriodMillis</code></a> and defaulting to every 1 second, FTDC will collect the output of the following commands:</p>

<ul>
<li><a href="https://docs.mongodb.com/manual/reference/command/serverStatus/"><code>serverStatus</code></a>: <code>db.serverStatus({tcmalloc: true})</code></li>
<li><a href="https://docs.mongodb.com/manual/reference/command/replSetGetStatus/"><code>replSetGetStatus</code></a>: <code>rs.status()</code></li>
<li><a href="https://docs.mongodb.com/manual/reference/command/collStats/"><code>collStats</code></a> for the <a href="https://docs.mongodb.com/manual/reference/local-database/#local.oplog.rs"><code>local.oplog.rs</code></a> collection (<a href="https://docs.mongodb.com/manual/reference/program/mongod/#bin.mongod">mongod</a> only)</li>
<li><a href="https://docs.mongodb.com/manual/reference/command/connPoolStats/#dbcmd.connPoolStats"><code>connPoolStats</code></a> (<a href="https://docs.mongodb.com/manual/reference/program/mongos/#bin.mongos">mongos</a> only)</li>
</ul>


<p>When FTDC is enabled (per <a href="https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionEnabled"><code>diagnosticDataCollectionEnabled</code></a>), the <code>metrics.xxxxxxx</code> files will be stored in <a href="https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionDirectoryPath"><code>diagnosticDataCollectionDirectoryPath</code></a> which by default is the <em>diagnostic.data</em> directory within the <a href="https://docs.mongodb.com/manual/reference/configuration-options/#systemLog.path"><code>systemLog.path</code></a>.</p>

<p>With <a href="https://jira.mongodb.org/browse/SERVER-21818">SERVER-21818</a> (introduced in MongoDB 3.2.13) and <a href="https://jira.mongodb.org/browse/SERVER-31400">SERVER-31400</a> (introduced in MongoDB 3.4.16) the diagnostic data capture scope was broadened to not only include internal diagnostic commands but system metrics as well. Depending on the host operating system, the diagnostic data may include one or more of the following statistics:</p>

<ul>
<li>CPU utilization (ex: <a href="http://www.linuxhowtos.org/System/procstat.htm"><code>/proc/stat</code></a>)</li>
<li>Memory utilization (ex: <a href="https://www.thegeekdiary.com/understanding-proc-meminfo-file-analyzing-memory-utilization-in-linux/"><code>/proc/meminfo</code></a>)</li>
<li>Disk utilization related to performance (ex: <a href="https://www.kernel.org/doc/Documentation/block/stat.txt"><code>*/sys/block/\*/stat*</code></a>)</li>
<li>Network performance statistics (<a href="https://unix.stackexchange.com/questions/435579/is-there-documentation-for-proc-net-netstat-and-proc-net-snmp"><code>/proc/net/netstat</code></a>)</li>
</ul>


<p>The <code>metrics.xxxxxxx</code> files in the <code>diagnostic.data</code> directory contain only statistics about the performance of the system and the database. They are stored in a compressed format, and are not human-readable.</p>

<p>Just a quick note regarding privacy, regardless of the version, the data in <em>diagnostic.data</em> never contains:</p>

<ul>
<li>Samples of queries, query predicates, or query results</li>
<li>Data sampled from any end-user collection or index</li>
<li>System or MongoDB user credentials or security certificates</li>
</ul>


<p>FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the <code>mongod</code> or <code>mongos</code>. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be <a href="https://en.wikipedia.org/wiki/Personal_data">Personally Identifiable Information (PII)</a>.</p>

<p>If you want to have a closer look at the diagnostic data collection process, you can inspect the <a href="https://github.com/mongodb/mongo/tree/master/src/mongo/db/ftdc">FTDC code</a>.</p>

<h2>FTDC Structure</h2>

<!-- MORE -->


<p>There are two types of FTDC documents: a <a href="https://github.com/mongodb/mongo/blob/r4.2.3/src/mongo/db/ftdc/util.h#L136">BSON metadata document</a>, or a <a href="https://github.com/mongodb/mongo/blob/r4.2.3/src/mongo/db/ftdc/util.h#L150">BSON metric chunk</a>.</p>

<p>Each document is made up of an <code>_id</code>, a <code>type</code> and either a <code>doc</code> or <code>data</code> field. The <code>type</code> field is used to identify the document type:</p>

<ul>
<li>0: Metadata Document</li>
<li>1: Metric Chunk</li>
</ul>


<p>The <code>doc</code> or <code>data</code> fields will contain &ldquo;samples&rdquo; in the form of:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span> <span class="cm">/* Time at which all collecting started */</span>
</span><span class='line'>  <span class="s2">&quot;name&quot;</span> <span class="o">:</span> <span class="nb">String</span><span class="p">,</span> <span class="cm">/* name is from name() in FTDCCollectorInterface */</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>        <span class="s2">&quot;start&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span> <span class="cm">/* Time at which name() collection started */</span>
</span><span class='line'>        <span class="s2">&quot;data&quot;</span> <span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>   <span class="cm">/* data comes from collect() in FTDCCollectorInterface */</span>
</span><span class='line'>        <span class="s2">&quot;end&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>   <span class="cm">/* Time at which name() collection ended */</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="p">...</span> <span class="cm">/* more than 1 collector be sampled */</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span> <span class="cm">/* Time at which all collecting ended */</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Samples are <a href="https://github.com/mongodb/mongo/blob/r4.2.3/src/mongo/db/ftdc/collector.h#L110">collected by <code>FTDCCollectorInterface</code></a> instances.</p>

<h3>Metadata Document</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;_id&quot;</span><span class="o">:</span>  <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;type&quot;</span><span class="o">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;doc&quot;</span><span class="o">:</span>  <span class="p">{</span> <span class="p">..</span> <span class="p">}</span> <span class="cm">/* Samples from collectors */</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>On log rotation or startup, the first FTDC entry will be collected and stored. This is a BSON document that contains information sampled by running <a href="https://docs.mongodb.com/manual/reference/command/getCmdLineOpts/"><code>getCmdLineOpts</code></a>, <a href="https://docs.mongodb.com/manual/reference/command/buildInfo/"><code>buildInfo</code></a> and <a href="https://docs.mongodb.com/manual/reference/command/hostInfo/"><code>hostInfo</code></a>.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// example</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span><span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;buildInfo&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;getCmdLineOpts&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;hostInfo&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span><span class="o">:</span> <span class="nx">DateTime</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This sample will be stored in the <code>doc</code> field of the metadata document.</p>

<h3>Metric Chunk</h3>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;_id&quot;</span><span class="o">:</span>  <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;type&quot;</span><span class="o">:</span> <span class="mi">1</span>
</span><span class='line'>  <span class="s2">&quot;data&quot;</span><span class="o">:</span> <span class="nx">BinData</span><span class="p">(...)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>During each collection interval (as configured by <a href="https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionPeriodMillis"><code>diagnosticDataCollectionPeriodMillis</code></a>), a metric chunk will be created and a sample will be collected, compressed and stored to the <code>data</code> document as Binary Data.</p>

<p>This sample can contain the results of internal commands such as <a href="https://docs.mongodb.com/manual/reference/command/serverStatus/"><code>serverStatus</code></a>,<a href="https://docs.mongodb.com/manual/reference/command/replSetGetStatus/"><code>replSetGetStatus</code></a>, <a href="https://docs.mongodb.com/manual/reference/command/collStats/"><code>collStats</code></a> for the <a href="https://docs.mongodb.com/manual/reference/local-database/#local.oplog.rs"><code>local.oplog.rs</code></a> collection or <a href="https://docs.mongodb.com/manual/reference/command/connPoolStats/#dbcmd.connPoolStats"><code>connPoolStats</code></a>, as well as external system metrics.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// example</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span><span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;serverStatus&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;connPoolStats&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;systemMetrics&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span><span class="o">:</span> <span class="nx">DateTime</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Decoding FTDC <code>metrics.xxxxxxx</code> files</h2>

<p>FTDC files, such as the <code>metrics.2019-10-28T19-02-23Z-00000</code> example file we&rsquo;ll be working with below are just <a href="http://bsonspec.org/">BSON</a> files. As such, the <a href="https://docs.mongodb.com/manual/reference/program/bsondump/"><code>bsondump</code></a> utility can be used to inspect the contents:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">METRICS</span><span class="o">=</span>metrics.2019-10-28T19-02-23Z-00000
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> less
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://www.alexbevi.com/images/ftdc-001.png"></p>

<p><code>bsondump</code> will default to emitting JSON, so we can interact with this using the <a href=""><code>jq</code></a> utility. For example, if we only want to review the <em>Metadata Document</em> this could be done as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># bsondump &lt; 4.0</span>
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> jq -s <span class="s1">&#39;.[] | select( .type == 0)&#39;</span> <span class="p">|</span> less
</span><span class='line'>
</span><span class='line'><span class="c"># bsondump &gt;= 4.0</span>
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> jq -s <span class="s1">&#39;.[] | select( .type | .&quot;$numberInt&quot; == &quot;0&quot;)&#39;</span> <span class="p">|</span> less
</span></code></pre></td></tr></table></div></figure>


<p><img src="http://www.alexbevi.com/images/ftdc-002.png"></p>

<p>Working with <em>Metric Chunks</em> is a little more complicated as they are actually zlib compressed BSON documents. We&rsquo;ll use the <code>jq</code> utility to only select the first chunk and the <a href="https://www.ruby-lang.org/en/">Ruby</a> interpreter to decompress the zlib data. Note that the following command can be altered to navigate to other chunks (not only the first) as needed:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># bsondump &lt; 4.0</span>
</span><span class='line'><span class="nv">METRICS</span><span class="o">=</span>metrics.2019-12-20T14-22-56Z-00000
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;.[] | select( .type == 1)&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;first | .data .&quot;$binary&quot;&#39;</span> -Mc <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  ruby -rzlib -rbase64 -e <span class="s1">&#39;d = STDIN.read; print Zlib::Inflate.new.inflate(Base64.decode64(d)[4..-1])&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  bsondump --quiet
</span><span class='line'>
</span><span class='line'><span class="c"># bsondump &gt;= 4.0</span>
</span><span class='line'><span class="nv">METRICS</span><span class="o">=</span>metrics.2019-12-20T14-22-56Z-00000
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;.[] | select( .type | .&quot;$numberInt&quot; == &quot;1&quot;)&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;first | .data .&quot;$binary&quot; .base64&#39;</span> -Mc <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  ruby -rzlib -rbase64 -e <span class="s1">&#39;d = STDIN.read; print Zlib::Inflate.new.inflate(Base64.decode64(d)[4..-1])&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  bsondump --quiet
</span></code></pre></td></tr></table></div></figure>


<p>You eagle-eyed Rubyists will notice that we&rsquo;re clipping the first 4 bytes from the binary data we&rsquo;re reading from STDIN. This is to drop the header before we try to decompress the stream.</p>

<p>If you don&rsquo;t do this <a href="https://www.zlib.net/">zlib</a> will complain and fail:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
</span><span class='line'>        1: from -e:1:in <span class="sb">`</span>&lt;main&gt;<span class="s1">&#39;</span>
</span><span class='line'><span class="s1">-e:1:in `inflate&#39;</span>: incorrect header check <span class="o">(</span>Zlib::DataError<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>The binary data has now been decompressed, and being BSON data we run it through <code>bsondump</code> again and voila:</p>

<p><img src="http://www.alexbevi.com/images/ftdc-003.png"></p>

<p>Hopefully this helps shed some light on what FTDC data is and what it contains. In a future post we&rsquo;ll look into doing something useful with this treasure trove of telemetry our clusters are generating every 1 second or so.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Troubleshooting and Fixing Invariant Failure !_featureTracker on MongoDB Startup]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/23/troubleshooting-and-fixing-invariant-failure-featuretracker/"/>
        <updated>2020-01-23T05:34:53-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/23/troubleshooting-and-fixing-invariant-failure-featuretracker</id>
        <content type="html"><![CDATA[<p>I recently found myself troubleshooting another <a href="https://www.mongodb.com/">MongoDB</a> startup issue due to potential corruption within a <a href="https://docs.mongodb.com/manual/core/wiredtiger/">WiredTiger</a> file. As I have previously covered this topic (see <a href="http://www.alexbevi.com/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/">&ldquo;Recovering a WiredTiger collection from a corrupt MongoDB installation&rdquo;</a>), I wanted to share the diagnostic and troubleshooting journey in case it helps anyone who experiences this issue in the future.</p>

<p>To ensure I could troubleshoot this issue in isolation, I first collected a backup of the necessary files from the affected installation as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tar -czvf metadata.tar.gz --exclude<span class="o">=</span>WiredTigerStat* WiredTiger* _mdb_catalog.wt sizeStorer.wt
</span></code></pre></td></tr></table></div></figure>


<p>Once I had this backup I extracted it to a new location, then using <a href="https://github.com/aheckmann/m">m</a> to select the versions of MongoDB to use tried to startup a standalone instance to see if I could reproduce the issue:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mkdir -p /tmp/repro
</span><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'><span class="c"># move archive from earlier to the new directory first</span>
</span><span class='line'>tar xvf metadata.tar.gz
</span><span class='line'><span class="c"># This is the version of MongoDB reported to be crashing</span>
</span><span class='line'>m 3.4.18
</span><span class='line'>mongod --dbpath .
</span></code></pre></td></tr></table></div></figure>


<p>Once the <code>mongod</code> started, we were able to see the failure and the process aborts (clipped log sample below).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2020-01-23T03:58:19.828-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> db version v3.4.18
</span><span class='line'>2020-01-23T03:58:19.828-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> git version: 4410706bef6463369ea2f42399e9843903b31923
</span><span class='line'>...
</span><span class='line'>2020-01-23T03:58:20.187-0500 I -        <span class="o">[</span>initandlisten<span class="o">]</span> Invariant failure !_featureTracker src/mongo/db/storage/kv/kv_catalog.cpp 305
</span><span class='line'>2020-01-23T03:58:20.187-0500 I -        <span class="o">[</span>initandlisten<span class="o">]</span>
</span><span class='line'>
</span><span class='line'>***aborting after invariant<span class="o">()</span> failure
</span><span class='line'>
</span><span class='line'>2020-01-23T03:58:20.198-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Got signal: <span class="m">6</span> <span class="o">(</span>Aborted<span class="o">)</span>.
</span><span class='line'>...
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo15printStackTraceERSo+0x41<span class="o">)</span> <span class="o">[</span>0x55bb45c92111<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x153F329<span class="o">)</span> <span class="o">[</span>0x55bb45c91329<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x153F80D<span class="o">)</span> <span class="o">[</span>0x55bb45c9180d<span class="o">]</span>
</span><span class='line'> libpthread.so.0<span class="o">(</span>+0x12890<span class="o">)</span> <span class="o">[</span>0x7f5b7bee5890<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>gsignal+0xC7<span class="o">)</span> <span class="o">[</span>0x7f5b7bb20e97<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>abort+0x141<span class="o">)</span> <span class="o">[</span>0x7f5b7bb22801<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo17invariantOKFailedEPKcRKNS_6StatusES1_j+0x0<span class="o">)</span> <span class="o">[</span>0x55bb44f5b234<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo9KVCatalog4initEPNS_16OperationContextE+0x568<span class="o">)</span> <span class="o">[</span>0x55bb458db5e8<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo15KVStorageEngineC1EPNS_8KVEngineERKNS_22KVStorageEngineOptionsE+0x807<span class="o">)</span> <span class="o">[</span>0x55bb458e79f7<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x124DFFA<span class="o">)</span> <span class="o">[</span>0x55bb4599fffa<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo20ServiceContextMongoD29initializeGlobalStorageEngineEv+0x697<span class="o">)</span> <span class="o">[</span>0x55bb45891627<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x7F62AC<span class="o">)</span> <span class="o">[</span>0x55bb44f482ac<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>main+0x96B<span class="o">)</span> <span class="o">[</span>0x55bb44f66a6b<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>__libc_start_main+0xE7<span class="o">)</span> <span class="o">[</span>0x7f5b7bb03b97<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x86FFB1<span class="o">)</span> <span class="o">[</span>0x55bb44fc1fb1<span class="o">]</span>
</span><span class='line'>-----  END BACKTRACE  -----
</span><span class='line'>Aborted <span class="o">(</span>core dumped<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>




<!-- more -->


<p>The <code>mongod</code> is failing to startup successfully due to an invariant failure during <code>KVCatalog::init</code>. We are able to determine this as the <code>mongod</code> log above tells us:</p>

<ol>
<li>The MongoDB version in used (3.4.18)</li>
<li>The path to the source file where the failure occurred (file: <code>src/mongo/db/storage/kv/kv_catalog.cpp</code>, line: 305)</li>
</ol>


<p>As MongoDB is open source, we can view the source for this release by going to <a href="https://github.com/mongodb/mongo/blob/r3.4.18/src/mongo/db/storage/kv/kv_catalog.cpp#L305,">https://github.com/mongodb/mongo/blob/r3.4.18/src/mongo/db/storage/kv/kv_catalog.cpp#L305,</a> which will show us the following:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">FeatureTracker</span><span class="o">::</span><span class="n">isFeatureDocument</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// There should be at most one version document in the catalog.</span>
</span><span class='line'>    <span class="n">invariant</span><span class="p">(</span><span class="o">!</span><span class="n">_featureTracker</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Initialize the feature tracker and skip over the version document because it doesn&#39;t</span>
</span><span class='line'>    <span class="c1">// correspond to a namespace entry.</span>
</span><span class='line'>    <span class="n">_featureTracker</span> <span class="o">=</span> <span class="n">FeatureTracker</span><span class="o">::</span><span class="n">get</span><span class="p">(</span><span class="n">opCtx</span><span class="p">,</span> <span class="k">this</span><span class="p">,</span> <span class="n">record</span><span class="o">-&gt;</span><span class="n">id</span><span class="p">);</span>
</span><span class='line'>    <span class="k">continue</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The comment preceding the invariant<sup id="f1"><a href="#fn1">1</a></sup> indicates that there&rsquo;s only one feature document to be present in the catalog, but what&rsquo;s the catalog?</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ls -l *catalog*
</span><span class='line'>-rw-r--r-- <span class="m">1</span> alex <span class="m">249856</span> Jan <span class="m">23</span> 03:58 _mdb_catalog.wt
</span></code></pre></td></tr></table></div></figure>


<p>As there&rsquo;s only one file that contains the word &ldquo;catalog&rdquo; this is good a place as any to start. The <code>_mdb_catalog</code> is a WiredTiger file, so to interact with it directly (outside of MongoDB) we will need to use the <a href="http://source.wiredtiger.com/mongodb-3.4/command_line.html">WiredTiger command line utility</a>, also know as <code>wt</code>.</p>

<p>The documentation link for <code>mongodb-3.4</code> points us to WiredTiger 2.9.2, so following the <a href="http://source.wiredtiger.com/mongodb-3.4/build-posix.html">build and installation instructions</a> we compile a <code>wt</code> binary with support for the snappy compressor. This is due to MongoDB&rsquo;s WiredTiger storage engine using snappy as the default block compressor (see <a href="https://docs.mongodb.com/manual/core/wiredtiger/#compression">&ldquo;Compression&rdquo;</a>).</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'>git clone git://github.com/wiredtiger/wiredtiger.git
</span><span class='line'><span class="nb">cd </span>wiredtiger
</span><span class='line'>git checkout 2.9.2
</span><span class='line'>sh autogen.sh
</span><span class='line'><span class="c"># ensure you have the necessary development headers for the snappy compression</span>
</span><span class='line'><span class="c"># library before compiling</span>
</span><span class='line'>./configure --enable-snappy <span class="o">&amp;&amp;</span> make
</span></code></pre></td></tr></table></div></figure>


<p>Once we&rsquo;ve successfully build the <code>wt</code> utility with snappy compression we can dump our catalog to see if we can find a duplicate entry for the feature document.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'><span class="c"># to shorten the amount of typing required, wrap the wt utility invocation in</span>
</span><span class='line'><span class="c"># a function we can call instead</span>
</span><span class='line'>WT<span class="o">()</span> <span class="o">{</span> /tmp/repro/wiredtiger/wt -v -C <span class="s2">&quot;extensions=[\&quot;/tmp/repro/wiredtiger/ext/compressors/snappy/.libs/libwiredtiger_snappy.so\&quot;]&quot;</span> <span class="nv">$@</span><span class="p">;</span> <span class="o">}</span>
</span><span class='line'><span class="c"># write the catalog dump out to a file</span>
</span><span class='line'>WT dump _mdb_catalog &gt; dump.dat
</span></code></pre></td></tr></table></div></figure>


<p>NOTE: If you receive the following error, just re-run the command.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>1579773800:589375<span class="o">][</span>9348:0x7fc9a8e17140<span class="o">]</span>, txn-recover: Recovery failed: WT_RUN_RECOVERY: recovery must be run to <span class="k">continue</span>
</span><span class='line'>wt: WT_RUN_RECOVERY: recovery must be run to <span class="k">continue</span>
</span></code></pre></td></tr></table></div></figure>


<p>This error is due to the presence of content in the <code>journal/</code> that was created when we last ran the <code>mongod</code>.</p>

<p>With the catalog dumped we can now search it for the feature document:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>grep isFeatureDoc dump.dat -B <span class="m">1</span> -n
</span><span class='line'>
</span><span class='line'>935-<span class="se">\c</span>2<span class="se">\e</span>5
</span><span class='line'>936:C<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>8isFeatureDoc<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>ans<span class="se">\0</span>0<span class="se">\1</span>2nonRepairable<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\1</span>2repairable<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0
</span><span class='line'>937-<span class="se">\c</span>2<span class="se">\e</span>6
</span><span class='line'>938:C<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>8isFeatureDoc<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>ans<span class="se">\0</span>0<span class="se">\1</span>2nonRepairable<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\1</span>2repairable<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0
</span></code></pre></td></tr></table></div></figure>


<p>INTERESTING! I&rsquo;m not really sure how the catalog was able to get into a state where two feature documents exist, but since we have a dump of the catalog let&rsquo;s try to remove one of those entries and then load the dump back into the catalog.</p>

<p>As the results appear to be identical, we&rsquo;ll just drop the first one and then try to load it back into the catalog.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># remove lines 935-936 and overwrite the file</span>
</span><span class='line'>sed -i -e <span class="s1">&#39;935,936d&#39;</span> dump.dat
</span><span class='line'><span class="c"># drop the contents of the _mdb_catalog table</span>
</span><span class='line'>WT truncate _mdb_catalog
</span><span class='line'><span class="c"># reload the table from the dump file</span>
</span><span class='line'>WT load -f dump.dat
</span></code></pre></td></tr></table></div></figure>


<p>If the table loaded successfully the output of the command should be something like <code>table:_mdb_catalog: 822</code>.</p>

<p>With a reloaded catalog, let&rsquo;s try spinning up the <code>mongod</code> again:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2020-01-23T05:24:54.911-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> db version v3.4.18
</span><span class='line'>...
</span><span class='line'>2020-01-23T05:24:56.247-0500 E STORAGE  <span class="o">[</span>initandlisten<span class="o">]</span> no cursor <span class="k">for</span> uri: table:SomeCollection/collection/34-1349843775853912065
</span><span class='line'>2020-01-23T05:24:56.247-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Invalid access at address: 0x58
</span><span class='line'>2020-01-23T05:24:56.259-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Got signal: <span class="m">11</span> <span class="o">(</span>Segmentation fault<span class="o">)</span>.
</span></code></pre></td></tr></table></div></figure>


<p>SUCCESS! The <code>mongod</code> is still crashing as the backing files for the database don&rsquo;t exist, but we should now be able to take our recovered files back to our node that was previously failing.</p>

<p>From our recovered directory compress the following files:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tar -czvf recovered.tar.gz --exclude<span class="o">=</span>WiredTigerStat* WiredTiger* _mdb_catalog.wt sizeStorer.wt
</span></code></pre></td></tr></table></div></figure>


<p>Note that if the <code>mongod</code> fails to start with the recovered files you may have to clear out the <code>journal/</code> directory.</p>

<p>Hopefully this helps someone someday ;)</p>

<p><em>If you enjoyed this post and like solving these types of problems, <a href="https://grnh.se/dcd90aac1">MongoDB is hiring!</a></em></p>

<hr/>


<p><small><b id="fn1">1</b> An invariant is a condition to test, that on failure will log the test condition, source file and line of code. <a href="#f1">↩</a></small></p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Current Date Math in MongoDB Aggregations]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/17/current-date-math-in-mongodb-aggregations/"/>
        <updated>2020-01-17T06:30:17-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/17/current-date-math-in-mongodb-aggregations</id>
        <content type="html"><![CDATA[<p>A challenge that I&rsquo;ve had in the past while working with my data in MongoDB has been how to incorporate
date math into my aggregations.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">insertMany</span><span class="p">([</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="p">},</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">5</span><span class="p">))</span> <span class="p">},</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">9</span><span class="p">))</span> <span class="p">}</span>
</span><span class='line'><span class="p">]);</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">find</span><span class="p">();</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975da0&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-08T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>


<p>Given the 3 documents we&rsquo;ve setup above, if I wanted to filter a pipeline to only <a href="https://docs.mongodb.com/manual/reference/operator/aggregation/match"><code>$match</code></a>
documents that are newer than 1 week old, I would have to resort to using Javascript:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// compare lastUpdated to a new Javascript Date object set to</span>
</span><span class='line'><span class="c1">// 7 days from the current date</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">aggregate</span><span class="p">(</span>
</span><span class='line'><span class="p">{</span> <span class="nx">$match</span><span class="o">:</span>
</span><span class='line'>  <span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="p">{</span> <span class="nx">$gte</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">7</span><span class="p">))</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>


<p>Now if your pipeline is running in a non-Javascript environment, the <code>new Date()</code> call within the pipeline
would likely throw an exception.</p>

<p>If you&rsquo;re working with MongoDB 4.2 or newer though, a new <a href="https://docs.mongodb.com/manual/reference/aggregation-variables/#variable.NOW"><code>$$NOW</code> aggregation variable</a> is available that can be combined with existing pipeline operators to <a href="https://docs.mongodb.com/manual/reference/operator/aggregation/subtract/index.html"><code>$subtract</code></a> the number of milliseconds in the number of days to filter from the current date:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// compare lastUpdated to the number of milliseconds in</span>
</span><span class='line'><span class="c1">// 7 days subtracted from the current</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">aggregate</span><span class="p">(</span>
</span><span class='line'><span class="p">{</span> <span class="nx">$match</span><span class="o">:</span>
</span><span class='line'>  <span class="p">{</span> <span class="nx">$expr</span><span class="o">:</span>
</span><span class='line'>    <span class="p">{</span> <span class="nx">$let</span><span class="o">:</span>
</span><span class='line'>      <span class="p">{</span> <span class="nx">vars</span><span class="o">:</span>
</span><span class='line'>        <span class="p">{</span> <span class="nx">start</span><span class="o">:</span>
</span><span class='line'>          <span class="p">{</span> <span class="nx">$subtract</span><span class="o">:</span> <span class="p">[</span><span class="s2">&quot;$$NOW&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">86400000</span><span class="p">)]</span> <span class="p">}</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="k">in</span><span class="o">:</span> <span class="p">{</span> <span class="nx">$gte</span><span class="o">:</span> <span class="p">[</span><span class="s2">&quot;$lastUpdated&quot;</span><span class="p">,</span> <span class="s2">&quot;$$start&quot;</span><span class="p">]</span> <span class="p">}</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>


<p>I hope you find this as useful as I did. With each major release of MongoDB new features and functionality
are being introduced that reduce the &ldquo;hacks&rdquo; or &ldquo;workarounds&rdquo; we&rsquo;ve had to do in the past.</p>

<p>If you&rsquo;re looking for more MongoDB tips and tricks, head on over to Asya&rsquo;s <a href="http://www.kamsky.org/stupid-tricks-with-mongodb">Stupid Tricks With MongoDB</a>.</p>

<p>Let me know in the comments below if you have any questions, or if you found this useful.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Technical Services Engineering at MongoDB]]></title>
        <link href="http://www.alexbevi.com/blog/2018/10/01/technical-services-engineering-at-mongodb/"/>
        <updated>2018-10-01T15:39:28-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/10/01/technical-services-engineering-at-mongodb</id>
        <content type="html"><![CDATA[<p>The goal of this post is to provide a first hand account of what it means to be a <em>Technical Services Engineer</em> at <a href="https://www.mongodb.com/careers/jobs/791258">MongoDB</a>, as well as what the journey getting to this point has looked like for me.</p>

<h3>WHO AM I?</h3>

<p>I have been working in Application Development and Software Engineering for nearly two decades. I started off writing desktop applications in QuickBASIC and Turbo Pascal, then eventually in VB6, VB.NET, C++ and C#. When it was time to shift focus to web development I started off with HTML/JS/CSS (as we all do :P), then in Flash/AS3, Flex, Python, Ruby/Rails and Node.js.</p>

<p>I have been writing software since I was a kid, starting with some automation tools for my mom&rsquo;s business. I then moved on to building tools to help me cheat at various games I was playing at the time, and eventually got more into emulator programming and reverse engineering. I guess you could say I&rsquo;ve always loved solving problems programmatically, and especially enjoyed identifying opportunities for automation and custom tooling.</p>

<p>This led me down an informal DevOps track, as I was finding there was a need for optimization in the infrastructure layers that my applications were deployed to. This led me deeper into Linux internals, system administration and network operations.</p>

<p>While I was gaining these new skill-sets my primary focus was always on application development and delivery. Before coming to MongoDB I was working as a Development Lead / System Architect, but I found that my focus was always being drawn back to solving performance challenges at the infrastructure level.</p>

<!-- MORE -->


<h3>WHY MONGODB?</h3>

<p>I started working with MongoDB on a number of &ldquo;hobby&rdquo; projects around 2012. At the time I really only had experience with RDBMS', but due to the unstructured nature of the data I was working with decided to give this new technology a whirl.</p>

<p>I fell in love with the database almost immediately, and have since carried it forward to multiple new employers, as well as contract opportunities and consulting engagements.</p>

<p>The low barrier to entry from a development bootstrapping perspective made it the ideal backend for proof-of-concept development through to production deployment.</p>

<p>As a result of this increased activity with MongoDB, I found my self doing a lot more investigation into <a href="http://www.alexbevi.com/blog/2018/05/28/troubleshooting-a-mongodb-performance-issue/">performance issues</a> and <a href="http://www.alexbevi.com/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/">internals</a> (links are to blog posts of challenges I encountered and resolved).</p>

<h3>WHY TECHNICAL SERVICES?</h3>

<p>This was initially very challenging for me, as I had pre-conceived notions as to what &ldquo;technical services&rdquo; actually implied. The first thoughts that popped in my head were &ldquo;technical support&rdquo;, &ldquo;client support&rdquo;, &ldquo;call center style support&rdquo;, etc.</p>

<p>While researching this position I came across a blog post from about six years ago by a MongoDB employee who blogged about his experience as a Support Engineer (in this <a href="http://blog.markofu.com/2012/07/being-support-engineer-10gen-part-1.html">two</a> <a href="http://blog.markofu.com/2012/10/being-support-engineer-10gen-part-2.html">part</a> series).</p>

<p>I found his reasons for joining MongoDB (10gen at the time), description of what kinds of challenges the job poses on a daily basis and how there is a constant push for self improvement and continuing education to align with what I was looking for in a new opportunity.</p>

<h3>WHAT&rsquo;S A TECHNICAL SERVICES ENGINEER ON PAPER</h3>

<p>To answer this question, let&rsquo;s start off by analyzing the <a href="https://www.mongodb.com/careers/jobs/791258">job posting</a> that kicked off this journey for me in the first place.</p>

<p><img src="http://www.alexbevi.com/images/why_tse/why_tse_001.png"></p>

<p>So they&rsquo;re looking for people that are able to solve problems and communicate clearly. This could be a call center gig after all &hellip; oh wait, <em>experts in MongoDB related database servers, drivers, tools, services</em> &hellip; hrm, maybe there&rsquo;s a bit more to this.</p>

<p><img src="http://www.alexbevi.com/images/why_tse/why_tse_002.png"></p>

<p><em>Architecture, performance, recovery, security</em>, those are a lot more complex than what you would face in a traditional support role. What really sold me though was the <em>contribute to internal projects</em> statement, as this aligned perfectly with my desire for process improvement through custom tooling.</p>

<p><img src="http://www.alexbevi.com/images/why_tse/why_tse_003.png"></p>

<p>By the time I got to this point in the job posting I was already sold. MongoDB is either trying to staff their first tier support with ridiculously over-qualified employees, or Technical Services really isn&rsquo;t what I would have thought.</p>

<p>I proceeded to fill out the application, attach my resume and cover letter and crossed my fingers.</p>

<h3>WHAT&rsquo;S A TECHNICAL SERVICES ENGINEER IN PRACTICE</h3>

<p>After working with other TSEs for the past two months and having had an opportunity to handle some of my own cases I think I can shed a bit of light on what this role really entails.</p>

<h4>HOW IS IT A SUPPORT ROLE?</h4>

<p>A Technical Services Engineer interacts with MongoDB&rsquo;s clients via a support queue. This allows incoming &ldquo;cases&rdquo; to be prioritized and categorized to allow engineers to quickly identify what form of subject matter expertise may be required (ex: <code>Indexing</code>, <code>Replication</code>, <code>Sharding</code>, <code>Performance</code>, <code>Networking</code>, etc).</p>

<p>As a TSE you&rsquo;re responsible for claiming cases from a queue and providing feedback in a timely fashion that is clear, concise and technically accurate.</p>

<h4>HOW IS IT AN ENGINEERING ROLE?</h4>

<p>Here&rsquo;s the juicy part of this job. Although replying to client requests is the &ldquo;deliverable&rdquo; for a TSE, how you go about reproducing their issues requires a very deep understanding of MongoDB internals, software engineering, network engineering, infrastructure architecture and technical troubleshooting.</p>

<p>Depending on the type of issue, a reproduction is likely in store. These involve recreating the environment (locally or in the cloud) to either benchmark or replicate the identified client challenge. There is a vast library of tools available to TSEs for these types of tasks, but on some occasions the right tool for the job may not exist.</p>

<p>In these cases, you have an opportunity to write your own scripts or tools to parse logs, measure performance, record telemetry or verify a hypothesis. Although MongoDB doesn&rsquo;t require TSEs to have any programming experience, for those like me that come from product engineering it&rsquo;s refreshing to know there&rsquo;s still an opportunity to scratch the development itch.</p>

<p>With each case you learn more about the inner working of the database, the tools, the drivers and OS level performance.</p>

<h3>CONCLUSION?</h3>

<p>I&rsquo;m leaving the closing section here as a question, as the TSE role continues to be redefined and refined as new MongoDB products come on board and new challenges present themselves.</p>

<p>What will likely remain constant though is the need for new engineers to have the following characteristics:</p>

<ul>
<li>a passion for continuing technical education</li>
<li>a willingness to step outside their comfort zone</li>
<li>an interest in software engineering</li>
<li>an interest in network operations</li>
</ul>


<p>I encourage you to check out MongoDB&rsquo;s <a href="https://grnh.se/dcd90aac1">available jobs</a> if what I&rsquo;ve described here interests you (I swear HR is not putting me up to this &hellip;) as we could use more engineers like you in our ranks :)</p>

<p>Feel free to leave a comment below or shoot me an email at <a href="mailto:alex@alexbevi.com">alex@alexbevi.com</a> if you have any questions.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Hello MongoDB]]></title>
        <link href="http://www.alexbevi.com/blog/2018/08/14/hello-mongodb/"/>
        <updated>2018-08-14T15:31:04-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/08/14/hello-mongodb</id>
        <content type="html"><![CDATA[<p>As of August 13th, I am no longer a System Architect at DAC Group. I have a public post on <a href="https://www.linkedin.com/feed/update/urn:li:activity:6432589236368601088/">LinkedIn</a> that got some good traction, but to summarize it was time to move on.</p>

<p>I&rsquo;ve been a software engineer in some capacity or another for nearly 20 years now. The position I&rsquo;ve taken is as a <em>Technical Services Engineer</em>, which is more of a support role than an active development role.</p>

<p>The decision to make this move wasn&rsquo;t make lightly. I&rsquo;ve been working hands on with code or overseeing a team of developers on a day to day basis for most of my professional career. As such, I was also involved with software engineering, and this was no different in my role as a <em>System Architect</em>.</p>

<p>In that role, I was still committing code on a nearly daily basis. If not, I was performing code review, or working on a design for a new system or solution. I would consider this all to still be &ldquo;hands on&rdquo;, though I had found myself mired in DevOps work a lot more than I would have liked (there were not sufficient Linux Sysadmins available to assist with the type of server operations oversight that was required).</p>

<p>The role at MongoDB isn&rsquo;t a traditional &ldquo;Tech Support&rdquo; type of role, as it requires a strong knowledge of networking, databases, system design, programming and client services. I&rsquo;ve been a fan of the MongoDB server for over 8 years now, and have brought it along with me to several new consulting opportunities as well as the full time jobs I&rsquo;ve help. I believe very strongly in the quality of this product, as well as the peripheral products that they&rsquo;ve developed.</p>

<p>I think the time has come for a new adventure. This is the first step towards a new career journey with a new company, as opposed to an incremental move upwards within the same professional space.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Troubleshooting a MongoDB Performance Issue]]></title>
        <link href="http://www.alexbevi.com/blog/2018/05/28/troubleshooting-a-mongodb-performance-issue/"/>
        <updated>2018-05-28T09:14:03-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/05/28/troubleshooting-a-mongodb-performance-issue</id>
        <content type="html"><![CDATA[<p><strong>UPDATE (2018-06-28):</strong> <em>I actually sent a link to this article to the author of the previous blog post and in her reply she indicates that the improvements to cache management and checkpoint areas were more likely to have improved my situation. Just wanted to call out how approachable the MongoDB team is even with these one-off type issues :). Thanks Sue!</em></p>

<p><strong>UPDATE (2018-06-21):</strong> <em>As we were running MongoDB 3.0.15 while all these issues were going on it&rsquo;s entirely possible that the <a href="https://engineering.mongodb.com/post/breaking-the-wiredtiger-logjam-the-write-ahead-log-1-2">optimizations made to the write-ahead log of WiredTiger</a> may have also contributed to this improvement in performance :)</em></p>

<p>The following is an edited excerpt from an email I sent out internally about an intermittent performance issue we&rsquo;ve been experiencing for several years now. The daily processing challenges we&rsquo;ve been experiencing revolved around running server-side javascript in order to produce daily reports. As our data ingestion rates rose and our data processing needs climbed, our server performance continued to degrade. This would occur regardless of the size of the VMs we would spin up.</p>

<h3>Postmortem</h3>

<p>Our MongoDB cluster is configured with three (3) servers: 1x primary (write-enabled) and 2x secondaries (read-only). These are running on Azure DS14v2 VMs with 8TB of storage (8x 1TB striped via LVM as these were the largest premium SSD-based data disks available at the time).</p>

<p>Aside from the servers being scaled up periodically, this configuration has been constant since the inception of the product.</p>

<p>The only major upgrade came in the form of a migration from 2.6 to 3.0 in 2015. At the time this was a major shift as it required rewriting a number of the underlying system scripts as well as introducing LRS-based storage to try and squeeze some additional performance out of the disks. Why optimize for IOPS? Because the reporting platform was designed to copy a lot of data back and forth in order to generate reports segmented by dimension (&ldquo;Group&rdquo;, &ldquo;Company&rdquo;, &ldquo;Country&rdquo;, &ldquo;State&rdquo;, &ldquo;City&rdquo;).</p>

<p><img class="center" src="http://www.alexbevi.com/images/20180528-mongo-001.png"></p>

<p>This chart (48 hours sampled from 1 week ago) shows <em>Cache Usage</em> spiking and <em>Replication Lag</em> spiking. The cache spikes occur as new writes trigger index activity, which invalidates (dirties) cached memory and causes cache eviction.</p>

<!-- more -->


<p>This slows down the speed at which the secondaries can request data from the primary, which spikes the lag. When the secondaries request more data, it would lock up the primary, which in turn affected the primary server’s ability to ingest new content and write it to disk. The read/write buffers back up and new write requests are throttled.</p>

<p><strong>Note</strong> &mdash; As of MongoDB 4.0, <a href="https://www.mongodb.com/blog/post/mongodb-40-release-candidate-0-has-landed">non-blocking secondary reads</a> have been added to address these types of latency issues.</p>

<p>This type of cascading failure was almost exclusively seen when a large batch process was being run in the morning directly on the primary mongod instance in the mornings..</p>

<p><img class="center" src="http://www.alexbevi.com/images/20180528-mongo-002.png"></p>

<p>This chart (48 hours sampled from 2 weeks ago) shows similar behaviour. The vertical lines show points at which we were forced to restart instances or cycle the primary server in order to recover resources.</p>

<p>You’ll notice that cache usage hits a certain point on the primary (left) server after which we have to kill the instance. The replication lag on the secondaries is also inconsistent, which would lead us to believe that the consumption rates from the primary are being affected by either network performance or disk performance.</p>

<p>In the absence of dedicated DevOps, DBAs or Infrastructure Engineers, the development teams have spent a significant amount of time learning to tune and troubleshoot this installation. Due to lack of specialization though occasionally issues may be misdiagnosed.</p>

<p>We completed a significant upgrade on Tuesday that brings our cluster up to mongodb-server 3.4.15 (from 3.0.15). The 3.0 series was first introduced in March 2015, with an end of life of February 2018. As no further security updates are being released, we’ve been coordinating tests with the product development teams for the past 12 months in order to prepare for a major upgrade.</p>

<p>This involved the deprecation of client-side javascript calls, as well as rewriting several map/reduce operations as aggregation pipelines to ensure when the transition happened there was no sudden outage.</p>

<p>Now that we’ve been running 3.4 in production for a few days I checked the same 48 hour sample and found something interesting …</p>

<p><img class="center" src="http://www.alexbevi.com/images/20180528-mongo-003.png"></p>

<p>The cache usage has remained steady since we turned the instances on. The replication lag also hasn’t gone much higher than a minute in the past few days (this could creep up to over an hour in the past!).</p>

<p>These samples include report generation for all products as well, so they represent the same load. We’ll have to continue to monitor this, but the initial results seem to show that a lot of the pain we’ve been suffering through may have stemmed from outdated software.</p>

<p>The way the review report is generated is still extremely inefficient, but if we continue seeing results like this for the foreseeable future then the urgency of redesigning that product drops and can be properly managed.</p>

<p>Here are some lessons we learned as a result of this investigation:</p>

<p><strong>Measure Everything</strong> &mdash; Without proper telemetry in place, not only is it difficult to identify negative trends, but it’s almost impossible to showcase the success of any change or action.</p>

<p><strong>Understand Your Tech</strong>  &mdash; Whether you’re using hosted, provisioned, on-premise, containerized, PAAS or some other solution as part of the application architecture, make sure you really understand how to use it, and how to support it. When MongoDB was introduced to the project it was done so to fill a specific need. Once that need was filled, resourcing discussions surrounding maintainability and support should likely have been prioritized.</p>

<p><strong>Document Everything</strong>  &mdash; As discoveries are made, write them down and share them. Knowledge sharing is even more important when you’re dealing with issues that go beyond the standard requirements of &ldquo;application development&rdquo;.</p>

<p><strong>Ask For Help</strong> &mdash; When it becomes necessary to step outside your comfort zone to solve a problem, a fresh perspective can be welcome.</p>

<p>Hopefully this journey benefits someone else in a similar situation.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Setting up domain forwarding in hover.com]]></title>
        <link href="http://www.alexbevi.com/blog/2018/04/25/setting-up-domain-forwarding-in-hover-dot-com/"/>
        <updated>2018-04-25T15:27:08-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/04/25/setting-up-domain-forwarding-in-hover-dot-com</id>
        <content type="html"><![CDATA[<p>I&rsquo;ve known for a long time that when you navigate to my domain directly at <a href="http://alexbevi.com">alexbevi.com</a> that you would be redirected to a <a href="https://www.hover.com">Hover</a> placeholder page.</p>

<p>I&rsquo;ve meant to add a domain redirect for a long time but just never got around to it &hellip; until now.</p>

<p>If you log into your Hover control console at <code>https://www.hover.com/control_panel/domain/&lt;your domain&gt;</code>, you can just add the forward from the <em>Mangage Forwards</em> section.</p>

<ul>
<li>Click <strong>Create a Forward</strong></li>
<li>Select from the dropdown list</li>
<li>Enter the full url (<a href="http://...">http://...</a>) you would like requests to your domain to go to</li>
<li>Click <strong>Save Forward</strong></li>
</ul>


<p>After about 15 minutes this will be active and all requests to your domain will redirect to the url you&rsquo;ve selected.</p>

<p><img class="center" src="http://www.alexbevi.com/images/alexbevi-forward.png"></p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Redmine Plugin Extension and Development Still In Demand]]></title>
        <link href="http://www.alexbevi.com/blog/2017/10/03/redmine-plugin-extension-and-development-still-in-demand/"/>
        <updated>2017-10-03T20:38:12-04:00</updated>
        <id>http://www.alexbevi.com/blog/2017/10/03/redmine-plugin-extension-and-development-still-in-demand</id>
        <content type="html"><![CDATA[<p>It&rsquo;s been a <a href="http://www.alexbevi.com/blog/2016/03/23/redmine-plugin-extension-and-development-is-apparently-still-relevant/">while</a> since I last wrote about <a href="http://www.packtpub.com/redmine-plugin-extension-and-development/book">Redmine Plugin Extension and Development</a> so I thought I&rsquo;d give a quick update.</p>

<p>I have been sharing sales numbers whenever possible as a way of (hopefully) encouraging other authors to see that there is some money out there, even for obscure niche topics.</p>

<table>
<thead>
<tr>
<th> </th>
<th>Ebook</th>
<th>Print</th>
</tr>
</thead>
<tbody>
<tr>
<td>Q2/2017</td>
<td>17</td>
<td>12</td>
</tr>
<tr>
<td>Q1/2017</td>
<td>16</td>
<td>8</td>
</tr>
</tbody>
</table>


<p>This isn&rsquo;t a super lucrative endeavour, but considering I published this book three years ago and it&rsquo;s still in demand, I can&rsquo;t complain.</p>

<p>If I had more time on my hands I might look into writing about something a bit more &ldquo;in demand&rdquo;, like <a href="https://www.docker.com/">Docker</a> or <a href="https://www.microsoft.com/net/core">.NET Core</a> (random topics I&rsquo;m currently interested in :P).</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Turning an old Android Phone into a Plex Media Server + PVR]]></title>
        <link href="http://www.alexbevi.com/blog/2017/09/22/turning-an-old-android-phone-into-a-plex-media-server/"/>
        <updated>2017-09-22T21:55:53-04:00</updated>
        <id>http://www.alexbevi.com/blog/2017/09/22/turning-an-old-android-phone-into-a-plex-media-server</id>
        <content type="html"><![CDATA[<p>This is possibly a solution to a problem no one other than me has, but once in a while I like to challenge myself to see if something ridiculous is possible.</p>

<p>This time around I wanted to see if I could take my old <a href="http://www.gsmarena.com/motorola_moto_x_(2nd_gen)-6649.php">Moto X (2014)</a> and use it as a <a href="https://www.plex.tv/">Plex Media Server</a>.</p>

<p>I didn&rsquo;t want to just see if I could install Plex though; I wanted to see if it would be possible to actually run a PMS instance along with <a href="https://sonarr.tv/">Sonarr</a> to download content automatically for shows I&rsquo;m interested in.</p>

<p><img class="center" src="http://www.alexbevi.com/images/moto-plex/moto-plex-003.png"></p>

<p>This introduced a couple of challenges, as Sonarr would need to be run using <a href="http://www.mono-project.com/">Mono</a> (as it&rsquo;s a .NET project), I&rsquo;d need a Bittorrent client to actually download the content, and I&rsquo;d likely need to be running a <a href="https://github.com/Jackett/Jackett">Jackett</a> service to allow Sonarr to process request through sites like The Pirate Bay.</p>

<p>Finally, as the Moto X is an ARM device, all of our software will need to be capable of running on an ARM platform.</p>

<p>Note that this process (with some minor changes) can be used to get a Plex + Sonarr + Jackett + Filebot + Transmission setup done on any Linux distribution. I just thought it would be fun to do it using a phone.</p>

<!-- more -->


<h2>Setup the Phone</h2>

<p>This was the easiest part, as it simply required rooting the device so we could install <a href="https://download.chainfire.eu/696/supersu/">SuperSU</a>.</p>

<p><img class="right" src="http://www.alexbevi.com/images/moto-plex/moto-plex-001.png"></p>

<p>With a factory reset instance and root access, the next step was to install <a href="https://play.google.com/store/apps/details?id=stericson.busybox&amp;hl=en">BusyBox</a> and <a href="https://play.google.com/store/apps/details?id=ru.meefik.linuxdeploy&amp;hl=en">Linux Deploy</a>.</p>

<p>Once both are installed from the Play Store, run Busy Box and select <em>Install</em>. You should only have to run this once, as it just installs a handful of Unix tools that Linux Deploy will need for the next step.</p>

<p>Linux Deploy will require a bit more configuration as you need to tweak it a bit to suit your needs.</p>

<p>First, select the repository you&rsquo;d like. For my phone I went with <strong>ubuntu-lxde_arm</strong>, as this would setup an Ubuntu 16.04 LXDE distro along with VNC and SSH. Those will come into play when we want to start setting up Sonarr and Plex.</p>

<p>Under the properties for the repository (the settings icon in the lower right next to the <em>Stop</em> button) I set the <em>Installation type</em> to <strong>Directory</strong>. This setting allows use to have access to all available storage on our device. The first time I tried this I used the default of <strong>File</strong>, which only gave me 2GB of storage to play with. Once the base installation was done, there wasn&rsquo;t enough space left for me to do much. I tried tweaking the <em>Image Size (MB)</em> setting and starting over but it didn&rsquo;t make a difference. Your milage may vary, so feel free to try other configurations.</p>

<p><img class="left" src="http://www.alexbevi.com/images/moto-plex/moto-plex-002.png"></p>

<p>Next, from the top-right menu you need to <em>Install</em> the selected repository. This will do the basic installation of the Linux distribution you selected and pre-configure it for SSH and VNC access.</p>

<p>Once installed, click on the <strong>Start</strong> button to boot up the image. After a lot of terminal scrolling, you&rsquo;ll see something along the lines of <code>&lt;&lt;&lt; start</code> on the last line and the text will stop. This is our signal to start setting up our software.</p>

<p>We&rsquo;ve now got Linux running alongside Android on our phone. Let&rsquo;s SSH into it and continue. The credentials are available under the repository properties. You can change these prior to installation or just use the defaults that are generated.</p>

<h2>Setting Up Plex</h2>

<p>There isn&rsquo;t an official ARM distribution of Plex, but thanks to some great work by <a href="https://github.com/uglymagoo/plexmediaserver-installer">Jan Friedrich</a>, we can easily patch the Plex NAS distribution for ARM or ARM64.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-get install -y fakeroot git
</span><span class='line'>git clone https://github.com/uglymagoo/plexmediaserver-installer
</span><span class='line'><span class="nb">cd </span>plexmediaserver-installer
</span><span class='line'>mkdir ../plex-installer<span class="p">;</span> git archive master <span class="p">|</span> tar -x -C ../plex-installer/
</span><span class='line'><span class="nb">cd</span> ..<span class="p">;</span> fakeroot dpkg-deb --build plex-installer ./
</span></code></pre></td></tr></table></div></figure>


<p>This will create a Debian package that can be installed directly. For me, it produced <code>plexmediaserver-installer_1.9.1.4272-b207937f1-2_armhf.deb</code>, so installation was done using:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo dpkg -i plexmediaserver-installer_1.9.1.4272-b207937f1-2_armhf.deb
</span></code></pre></td></tr></table></div></figure>


<p>Then, to start up your Plex Media Server:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>start_pms
</span></code></pre></td></tr></table></div></figure>


<p>You can verify it by going to <a href="http://phone-ip:32400/web/index.html.">http://phone-ip:32400/web/index.html.</a></p>

<p>I&rsquo;m not going to set anything up here yet as we first need our media source available, which we&rsquo;ll be doing next.</p>

<h2>Setting Up Sonarr and Jackett</h2>

<p>Sonarr can be installed from a repository list, so we&rsquo;ll just set that up on our phone. Sonarr will also require Mono to be installed, which luckily for us is also available from Ubuntu compiled for armhf.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-get install -y libmono-cil-dev mono-devel libcurl4-openssl-dev
</span><span class='line'>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FDA5DFFC
</span><span class='line'>
</span><span class='line'>sudo <span class="nb">echo</span> <span class="s2">&quot;deb http://apt.sonarr.tv/ master main&quot;</span> <span class="p">|</span> sudo tee /etc/apt/sources.list.d/sonarr.list
</span><span class='line'>sudo apt-get update
</span><span class='line'>sudo apt-get install -y nzbdrone
</span></code></pre></td></tr></table></div></figure>


<p><img class="center" src="http://www.alexbevi.com/images/moto-plex/moto-plex-004.png"></p>

<p>Before we configure Sonarr, we&rsquo;ll setup Jackett. Jackett can be used to connect a torrent search site as a <a href="https://github.com/Sonarr/Sonarr/wiki/Supported-Indexers#torznab">Torznab feed</a> to Sonarr.</p>

<p>For the purposes of this test I just setup The Pirate Bay, but Jackett supports a number of sites that may better suit your needs ;)</p>

<p>To start Jackett, we&rsquo;ll need to run it using Mono:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mono --debug ~/Jackett/JackettConsole.exe
</span></code></pre></td></tr></table></div></figure>


<p>Jackett will be available at <a href="http://phone-ip:9117.">http://phone-ip:9117.</a> Once you&rsquo;ve configured a search site in Jackett, you can start Sonarr and begin configuration.</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mono --debug ~/Jackett/JackettConsole.exe
</span></code></pre></td></tr></table></div></figure>


<p>Sonarr will start up at <a href="http://phone-ip:8989.">http://phone-ip:8989.</a> First we&rsquo;ll setup an <em>Indexer</em> (from <em>Settings -> Indexers</em>). This is where we&rsquo;ll plug in the details we configured in Jackett. You&rsquo;ll need exact url from Jackett, as well as the API key. This information is all easy to find from the Jackett interface.</p>

<p>Next, setup a TV show from the <em>Series</em> section. Once added we&rsquo;ll need to configure way to download content automatically when Sonarr detects a new episode. This is done under <em>Settings -> Download Client</em>.</p>

<p>Create a new <a href="https://transmissionbt.com/">Transmission</a> client, give it a name and leave the default settings.</p>

<p>The only issue now though is that we don&rsquo;t have Transmission setup &hellip;</p>

<h2>Setting Up Transmission and Filebot</h2>

<p>Both of these are going to be a bit challenging, as <a href="https://www.filebot.net/">Filebot</a> (which we&rsquo;ll be using to move and organize our downloads) needs <a href="https://www.java.com/en/">Java</a>, and Transmission requires a display server (can&rsquo;t be run from SSH).</p>

<p>First, let&rsquo;s install whatever we can from our existing SSH session:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo <span class="nb">echo</span> <span class="s2">&quot;deb http://ppa.launchpad.net/webupd8team/java/ubuntu precise main&quot;</span> <span class="p">|</span> sudo tee -a /etc/apt/sources.list
</span><span class='line'>sudo <span class="nb">echo</span> <span class="s2">&quot;deb-src http://ppa.launchpad.net/webupd8team/java/ubuntu precise main&quot;</span> <span class="p">|</span> sudo tee -a /etc/apt/sources.list
</span><span class='line'>sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys EEA14886
</span><span class='line'>sudo apt-get update
</span><span class='line'>sudo apt-get install -y curl oracle-java8-installer transmission
</span><span class='line'>curl -L -O https://downloads.sourceforge.net/project/filebot/filebot/FileBot_4.7.9/filebot_4.7.9_armhf.deb
</span><span class='line'>sudo dpkg -i  filebot_4.7.9_armhf.deb
</span></code></pre></td></tr></table></div></figure>


<p><strong>NOTE:</strong> if you get an error installing the key via <code>apt-key</code>, try the following:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys EEA14886
</span></code></pre></td></tr></table></div></figure>


<p>In order to use Filebot, we&rsquo;ll need a script we can call from Transmission. The script I&rsquo;m working with is as follows:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c">#!/bin/bash</span>
</span><span class='line'>filebot -non-strict -script fn:amc --output /home/android/Media --log-file /home/android/amc.log --action move --conflict auto --def <span class="nv">music</span><span class="o">=</span>n --def <span class="nv">subtitles</span><span class="o">=</span>n --def <span class="nv">artwork</span><span class="o">=</span>y --def <span class="nv">backdrops</span><span class="o">=</span>n --def <span class="nv">clean</span><span class="o">=</span>y <span class="s2">&quot;seriesFormat= /home/android/Media/TV/{n}/{fn}&quot;</span> <span class="s2">&quot;ut_dir=$TR_TORRENT_DIR/$TR_TORRENT_NAME&quot;</span> <span class="s2">&quot;ut_kind=multi&quot;</span> <span class="s2">&quot;ut_title=$TR_TORRENT_NAME&quot;</span>
</span></code></pre></td></tr></table></div></figure>


<p>This script assumes that (a) your home directory is <code>/home/android</code>, and (b) you will be storing your media for Plex at <code>/home/android/Media/TV</code>. Feel free to modify the values to fit your particular installation.</p>

<p>Let&rsquo;s save this script as <strong>transmission-postprocess</strong> and make it executable using <code>chmod +x transmission-postprocess</code>.</p>

<p>Next, we&rsquo;ll need to actually VNC into our Linux distro. This is due to Transmission being a GTK application so we&rsquo;ll need to interact with it in a desktop environment.</p>

<p><img class="center" src="http://www.alexbevi.com/images/moto-plex/moto-plex-005.png"></p>

<p>From the desktop, launch Transmission and go to <em>Edit -> Preferences</em>. We want to do two things now:</p>

<ul>
<li>Setup Remote Access</li>
<li>Under <em>Downloading</em> setup the script we created above to be called when a torrent completes</li>
</ul>


<h2>Putting It All Together</h2>

<p><img class="center" src="http://www.alexbevi.com/images/moto-plex/moto-plex-006.png">
<small>open in new tab to see full size</small></p>

<p>Going back to our Plex Media Server url, we can now setup a library that points to our downloaded media directory.</p>

<p>When Sonarr detects a new episode, it will send the torrent link it finds from our TPB indexer to Transmission, and on completion Filebot will analyze the file and move it to the appropriate series/season folder for the show that was downloaded.</p>

<p>Enjoy!</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Just Finished - Warcraft Adventures]]></title>
        <link href="http://www.alexbevi.com/blog/2016/11/29/just-finished-warcraft-adventures/"/>
        <updated>2016-11-29T04:36:22-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/11/29/just-finished-warcraft-adventures</id>
        <content type="html"><![CDATA[<p><img class="left" src="http://www.alexbevi.com/images/wca/wca.08.png"></p>

<p>Although I&rsquo;m a huge fan of the point-and-click adventure genre, I&rsquo;ve been primarily focusing on covering 16-bit RPGs in my spare time. I&rsquo;ve still got a sizeable backlog to wade through, but when the news dropped that <a href="https://en.wikipedia.org/wiki/Warcraft_Adventures:_Lord_of_the_Clans">Warcraft Adventures: Lord of the Clans</a> had been leaked, I couldn&rsquo;t resist.</p>

<p>Although no one really got a taste of this game until 2010 when MAN-biker posted some content to Youtube, I&rsquo;d been inquiring with Blizzard as early as 2008. I still have a copy of the email, so I&rsquo;ve trimmed it down a bit and shared it below.</p>

<!-- more --> 


<p><noscript><pre>From: <a href="&#109;&#x61;&#x69;&#108;&#116;&#111;&#58;&#97;&#x6c;&#x65;&#120;&#x62;&#101;&#118;&#105;&#64;&#x67;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;">&#x61;&#x6c;&#101;&#x78;&#98;&#x65;&#x76;&#105;&#x40;&#x67;&#109;&#x61;&#x69;&#108;&#46;&#99;&#111;&#109;</a>
To: <a href="&#109;&#97;&#105;&#108;&#116;&#x6f;&#x3a;&#119;&#x65;&#98;&#x2e;&#115;&#117;&#112;&#112;&#x6f;&#x72;&#116;&#64;&#98;&#108;&#x69;&#x7a;&#x7a;&#97;&#114;&#x64;&#x2e;&#99;&#111;&#x6d;">&#119;&#101;&#x62;&#46;&#115;&#117;&#112;&#112;&#x6f;&#114;&#x74;&#64;&#x62;&#108;&#105;&#122;&#x7a;&#97;&#114;&#100;&#x2e;&#99;&#x6f;&#109;</a>
Sent: 12/19/2008 11:58:55 AM
Subject: [en]Warcraft &ndash; Other</p>

<p>This isn&#39;t really a support question, and I have no idea how to route this
properly, but the question I want to ask is as follows:</p>

<p>Over the years, I&#39;m sure there have been numerous attempts by fans to get Blizzard
to revive the Warcraft Adventures project. The statement made when it was cancelled
was that it didn&#39;t meet the quality requirements that Blizzard was trying to keep
for it&#39;s users; and over the years, those decisions have resulted in excellent titles.</p>

<p>Regarding Warcraft Adventures though, it&#39;s been 10 years since this project was
cancelled. I don&#39;t have any inside information into the level of completion the
project was at, but if it was &#39;near&#39; completion, couldn&#39;t this be released to the
open-source community to be added to a project such as ScummVM? The benefit here
would be positive PR for Blizzard, as well as renewed interest in their catalog of
games to a number of new users.</p>

<p>I don&#39;t represent the ScummVM team, but I&#39;d be interested to know what you
guys think. -Alex</p>

<hr />

<p>From: &lt;petern.support@blizzard.com&gt;
To: &lt;alexbevi@gmail.com&gt;
Subject: Re: [en]Warcraft &ndash; Other
Date: Mon, 22 Dec 2008 18:49:29 -0800</p>

<p>Greetings Alex,</p>

<p>Thank you for emailing the Blizzard technical support department in regards
to your question.  I know the same question has been asked by others in the
past and unfortunately there just is not information in regards to the game
that I have available to give besides what is already available on the internet.<br/>
Unfortunately I have no way to request any further information about the game or
items such as art resources or code from the game.</p>

<p>The best place I can suggest to post such a request is on our suggestions forum
at <a href="http://forums.battle.net/board.html?forumId=12016&amp;amp;sid=3000.">http://forums.battle.net/board.html?forumId=12016&amp;amp;sid=3000.</a>  This is by employees
that have more information, and more access to information than we do here in
technical support, if there is a large enough interest in anything then those ideas
are passed along to those that may be able to do more.  I cant guarantee anything
unfortunately but this is the best location I can suggest to try for such a request.</p>

<p>Regards,
Peter N.
Technical support
Blizzard Entertainment</p>

<p><a href="http://www.blizzard.com/support">http://www.blizzard.com/support</a></p>

<p>If you reply, please include all previous text and files related to this e-mail.<br/>
Please note the Tech support email system does not support read receipts.</pre></noscript><script src="https://gist.github.com/alexbevi/790743a5b30963103596fa77f04fe75a.js"> </script></p>

<p>My hope was to get access to the source code for the <a href="http://www.scummvm.org/">ScummVM</a> team to be able to incorporate as a custom engine.</p>

<p>Unfortunately (though not unsurprisingly), Blizzard wouldn&rsquo;t release the code.</p>

<p>Now, once word got out that the complete game had been released (not legally I know &hellip;), I had to grab it and give it a shot.</p>

<p>Being a game from the late 90&rsquo;s, I didn&rsquo;t expect it to just work. My primary machines run Linux, so I first tried to run this through <a href="https://www.winehq.org/">wine</a>, which didn&rsquo;t end up working reliably.</p>

<p>I then built a Windows XP VM using VirtualBox. This managed to run
the game with no issues.</p>

<h3>Story</h3>

<p>As per the <a href="http://wow.gamepedia.com/Warcraft_Adventures:_Lord_of_the_Clans">Gamepedia</a> article:</p>

<p>Basically, after the Dark Portal was destroyed and the rift between the worlds was destroyed, you had a large group of orcs that were trapped on Azeroth. And over the course of the next few years, the humans, being merciful in their ways, instead of hunting down and eradicating these orcs, granted them land areas where they could live as long as they lived within the confines of societal expectations. Basically, they were put on these reservations or camps. And because they were made to live in a way that was very contrary to their basic nature, a lot of the spirit and fire that defines them as a culture was drained out of them. And so what you found yourself with was an orc society in Azeroth of forced passivity, not forced through violence but forced through situation.
Although down on their luck, the orcs in Warcraft Adventures were supposed to experience a rebirth, thanks to the leadership of Thrall.</p>

<p><img class="left" src="http://www.alexbevi.com/images/wca/wca.10.png"></p>

<p>Our storyline followed an orc baby that was taken from a battle scene where his parents were slain and raised by a human lieutenant, Blackmoore, with the intention of raising him with human ideals but being able to use him to control the orcs. Definitely someone who does not fit into the general stereotype of noble humans. He was a self-serving, dark human character who wanted to raise this orc, Thrall, our central character in the game, and use him to control and command the orcs and then raise them as his own private army. Thrall, though he&rsquo;s raised in captivity by humans to serve their will, still has some fire within him that he can&rsquo;t deny, so he rebels against his human owners. He escapes the compound where he&rsquo;s being held, and then over the course of the game, what we do is follow his adventures. As he discovers more about himself and the orcs and what it means to be an orc, so does the player. As you go through the game, you meet some familiar faces from the games, some in retirement, some trying to lead an underground resistance, and you learn of what happened to the Frost Wolf Clan, which was the clan that Thrall&rsquo;s father Durotan was a part of. You learn that Durotan, Blackhand and Doomhammer were three blood brothers, and that his clan Frost Wolf was sent into the Dwarf Highlands in the mountains. They were exiled there by a plotting Ner'zhul, when he was pulling the strings in the background behind Doom Hammer and Black Hand, because he knew that Durotan was a threat.</p>

<h3>Gameplay</h3>

<p>When I first started playing WCA, it was a nice trip down memory lane. The gameplay mechanics really seemed to borrow heavily from <a href="https://en.wikipedia.org/wiki/Full_Throttle_(1995_video_game)">Full Throttle</a>, which was one of my favourite point-and-click adventures in the &lsquo;90s.</p>

<p><img class="right" src="http://www.alexbevi.com/images/wca/wca.05.png"></p>

<p>Right-clicking brings up a graphical command menu that lets you talk, look or use.</p>

<p>You can interact with the environment based on designated hotspots (which are identified when hovered by showing a label).</p>

<p>Thrall will usually try to respond with a funny comment whenever possible, which makes it more compelling to click around and see what he has to say about his surroundings.</p>

<h3>Puzzles</h3>

<p>As with most adventure games of this era, the puzzles are predominantly fetch-quests and inventory manipulation quests. Again, if you grew up with these games this type of mechanic is old hat, but if you&rsquo;re new to the genre, this can seem a bit tedious.</p>

<p>I found that the puzzles were a bit on the easy side (until the last 10 minutes of the game). This could just be because I&rsquo;m used to these sorts of games, but until I need to dig around in the dragon&rsquo;s stomach for the pig&rsquo;s jetpack, everything was straightforward and I didn&rsquo;t feel the need to look to Google for the answer.</p>

<h2>Overall</h2>

<p>As a throwback to &lsquo;90s point-and-click adventures, I&rsquo;d say WCA is worth playing. If you enjoyed the genre, this is a no brainer, and if you&rsquo;ve never played this type of game, this is a pretty easy entry.</p>

<p>The version of the game that was leaked is pretty close to being completed. I didn&rsquo;t notice any issues or major omissions.</p>

<p>The quality of the FMVs are pretty low compared to other games from the late &lsquo;90s. The pacing of the game isn&rsquo;t too slow and the story is interesting enough to make you want to see it through to the end.</p>

<p>Playing Warcraft Adventures actually made me want to revisit some other adventure games. I get the urge to play through Day of the Tentacle every 4-5 years or so, and I think it&rsquo;s been almost that long &hellip;</p>

<div id="galleria"><img src="http://www.alexbevi.com/images/wca/wca.01.png" data-title="/images/wca/wca.01.png" /><img src="http://www.alexbevi.com/images/wca/wca.02.png" data-title="/images/wca/wca.02.png" /><img src="http://www.alexbevi.com/images/wca/wca.03.png" data-title="/images/wca/wca.03.png" /><img src="http://www.alexbevi.com/images/wca/wca.04.png" data-title="/images/wca/wca.04.png" /><img src="http://www.alexbevi.com/images/wca/wca.06.png" data-title="/images/wca/wca.06.png" /><img src="http://www.alexbevi.com/images/wca/wca.07.png" data-title="/images/wca/wca.07.png" /><img src="http://www.alexbevi.com/images/wca/wca.09.png" data-title="/images/wca/wca.09.png" /><img src="http://www.alexbevi.com/images/wca/wca.11.png" data-title="/images/wca/wca.11.png" /><img src="http://www.alexbevi.com/images/wca/wca.12.png" data-title="/images/wca/wca.12.png" /><img src="http://www.alexbevi.com/images/wca/wca.13.png" data-title="/images/wca/wca.13.png" /><img src="http://www.alexbevi.com/images/wca/wca.14.png" data-title="/images/wca/wca.14.png" /><img src="http://www.alexbevi.com/images/wca/wca.15.png" data-title="/images/wca/wca.15.png" /><img src="http://www.alexbevi.com/images/wca/wca.16.png" data-title="/images/wca/wca.16.png" /><img src="http://www.alexbevi.com/images/wca/wca.17.png" data-title="/images/wca/wca.17.png" /><img src="http://www.alexbevi.com/images/wca/wca.18.png" data-title="/images/wca/wca.18.png" /><img src="http://www.alexbevi.com/images/wca/wca.19.png" data-title="/images/wca/wca.19.png" /><img src="http://www.alexbevi.com/images/wca/wca.20.png" data-title="/images/wca/wca.20.png" /><img src="http://www.alexbevi.com/images/wca/wca.21.png" data-title="/images/wca/wca.21.png" /><img src="http://www.alexbevi.com/images/wca/wca.22.png" data-title="/images/wca/wca.22.png" /></div>


<script>  Galleria.configure('transition', 'fade');  Galleria.run('#galleria');</script>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Summer RPG Update 2016]]></title>
        <link href="http://www.alexbevi.com/blog/2016/09/05/summer-update-2016/"/>
        <updated>2016-09-05T14:08:29-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/09/05/summer-update-2016</id>
        <content type="html"><![CDATA[<p>I don&rsquo;t really have much progress to report for the last month, so I thought I&rsquo;d throw out a few of the games I&rsquo;ve been working through to see if I can generate any interest in the next article ;)</p>

<p><img class="left" src="http://www.alexbevi.com/images/goldensun/goldensun.016.png"></p>

<p>First off, I&rsquo;ve been playing through <a href="https://en.wikipedia.org/wiki/Golden_Sun">Golden Sun</a> for the GBA.</p>

<p>I really like the psyenergy system and how you use it for puzzle solving. It makes this game a bit more of an ARPG along the same lines as <a href="http://www.alexbevi.com/blog/2015/09/23/just-finished-lufia-2/">Lufia 2</a>.</p>

<p>I&rsquo;ve made it as far as <a href="http://goldensun.wikia.com/wiki/Kraken">Kraken</a>, but I&rsquo;m finding beating him is proving to be more difficult that I&rsquo;d expected. Probably going to have to back out and grind for a while, which I don&rsquo;t have a lot of time for &hellip;</p>

<p><img class="right" src="http://www.alexbevi.com/images/7th-saga/7th-saga.019.png"></p>

<p>Next, I&rsquo;m pretty sure I&rsquo;ve given up on <a href="https://en.wikipedia.org/wiki/The_7th_Saga">the 7th Saga</a>. I&rsquo;m still at Telaine with a party at level 17, but I&rsquo;m pretty sure that to progress, there is grinding in my future.</p>

<p>Similar to the situation I&rsquo;m having above with Golden Sun, i just need to set many hours aside to level up in order to proceed, but with the amount of time I&rsquo;ve got these days to devote to these games, that may never happen.</p>

<!-- more -->


<p>Finally, I&rsquo;ve decided to bite the bullet and dive into <a href="https://en.wikipedia.org/wiki/Super_Mario_RPG">Super Mario RPG</a>. This, along with Final Fantasy Tactics is one of those games that I&rsquo;ve heard nothing but good things about for the last 20 years, but have never bothered to investigate myself.</p>

<p><img class="left" src="http://www.alexbevi.com/images/mariorpg/mariorpg.011.png"></p>

<p>I&rsquo;m currently at level 10 with 3 star pieces recovered and have just rescued Princess Toadstool and had her join the party.</p>

<p>I&rsquo;m really enjoying the story and gameplay, but since this was developed by Square, I&rsquo;m not surprised that this is right up my alley :P</p>

<p>I&rsquo;m most likely going to be able to finish this game off, and then circle back around to Golden Sun, as I really want to beat that game.</p>

<p>Now, assuming I can make some progress on those two games, I&rsquo;d like to start getting some feedback on where to take this series next.</p>

<p>There are a number of games that I&rsquo;ve finished previously that I didn&rsquo;t write about. Some of the more notable ones would be:</p>

<ul>
<li><a href="https://en.wikipedia.org/wiki/Mother_3">Mother 3</a></li>
<li>Final Fantasy VIII</li>
<li>Final Fantasy IX</li>
<li>Chrono Trigger</li>
</ul>


<p>Then there&rsquo;s the list of games that I really want to tackle, but since they all require a sizable time investment I&rsquo;m not sure which to hit up:</p>

<ul>
<li>Xenogears</li>
<li>Breath of Fire 3</li>
<li><a href="https://en.wikipedia.org/wiki/Shin_Megami_Tensei:_Persona_3">Shin Megami Tensei: Persona 3</a> - <em>I&rsquo;d likely play the PSP release</em></li>
<li><a href="https://en.wikipedia.org/wiki/Danganronpa:_Trigger_Happy_Havoc">Danganronmpa</a> - <em>I started this a while back but never finished it</em></li>
<li><a href="https://en.wikipedia.org/wiki/Shin_Megami_Tensei_II">Shin Megami Tensei 2</a> - <em>There&rsquo;s a great fan translation of the Super Famicom release</em></li>
<li><a href="https://en.wikipedia.org/wiki/Final_Fantasy_IV:_The_After_Years">Final Fantasy IV: After Years</a></li>
<li><a href="https://en.wikipedia.org/wiki/Vagrant_Story">Vagrant Story</a></li>
</ul>


<p>If you&rsquo;ve got any insight into which I should tackle next, feel free to leave me a comment below ;)</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Just Finished - Dragon Quest I]]></title>
        <link href="http://www.alexbevi.com/blog/2016/07/27/just-finished-dragon-quest-i/"/>
        <updated>2016-07-27T22:26:01-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/07/27/just-finished-dragon-quest-i</id>
        <content type="html"><![CDATA[<p>I actually finished this game around the end of June, but haven&rsquo;t really had a chance to write about it until now. I&rsquo;m currently sitting out by the lake at the cottage and figured it was about time :P</p>

<p><img class="left" src="http://www.alexbevi.com/images/dq1/dq1.000.png"></p>

<p>The last time I played through Dragon Quest was likely in the late 80&rsquo;s. I&rsquo;m pretty sure I either heard about it, or got a copy of it through Nintendo Power, and like most kids in North America at the time, this would have been my first introduction to what would become known as JRPGs.</p>

<p>I decided to go with the SNES re-release of this title for my playthrough as I wanted some updated graphics and music. Although the SNES version was never officially localized for North America, there is an <a href="http://www.romhacking.net/translations/337/">excellent fan translation</a> available.</p>

<p>It threw me off a bit when they refer to the legendary hero as Roto (as opposed to Erdrick), but I&rsquo;m assuming this is a better translation than what we got in the 80&rsquo;s so that&rsquo;s probably what the name should have been in the first place.</p>

<p><img class="right" src="http://www.alexbevi.com/images/dq1/dq1.001.png"></p>

<p>Dragon Quest was essentially the first JRPG. As a result, there are a lot of concepts introduced here that would be adapted and refined by other titles and series over the years. This means that some parts of this game feel a bit rough or unbalanced.</p>

<p>I originally played the NES version of this title, and have fond memories of just how brutally hard it was. This game introduced me to what I would come to know as &ldquo;grinding&rdquo;, as you couldn&rsquo;t progress through the game unless your character was sufficiently leveled up in order to tackle the monsters in the areas you were exploring.</p>

<p>This meant walking back and forth and fighting random monsters.</p>

<p>Enemy encounter rates are high. Very high. I think the SNES version actually optimized this a bit, but the rates are still high. This is useful for grinding, but gets tedious when you want to explore, or really need to get back to a town to heal.</p>

<p>The story is pretty simple.</p>

<p>You&rsquo;re the descendant of the legendary hero, and have been tasked with rescuing the princess and defeating the Dragon Lord.</p>

<!-- more -->


<p><img class="left" src="http://www.alexbevi.com/images/dq1/dq1.001.png"></p>

<p>To defeat the Dragon Lord, you need to get three pieces of equipment of the legendary hero which are scattered across the world.</p>

<p>Beat the dragon. Save the princess. Beat the Dragon Lord. Done.</p>

<p>Gameplay is pretty straightforward. You start off in the castle, where the king explains your quest. You can talk to people in the castle, or leave and move on to the nearest town.</p>

<p>Here you&rsquo;ll get a bit more info, or can buy supplies.</p>

<p>I think it&rsquo;s kind of cool that the first time you leave the castle you can see the Dragon Lord&rsquo;s castle on the world map. This gives you your target right away and you know what you&rsquo;re working towards.</p>

<p>You interact with NPCs and the world via a command menu. One of the nice additions to the SNES version is that you no longer have to use a STAIRS command to go up and down stairs; just walk over them.</p>

<p><img class="right" src="http://www.alexbevi.com/images/dq1/dq1.012.png"></p>

<p>As you roam around the overworld and dungeouns, you&rsquo;ll get into random encounters. You interact with these using a command menu as well, where you can select to either attack, use magic, use an item, or run.</p>

<p>Dragon Quest is a pretty short game. Being one of the first of this genre it introduced a lot of gameplay elements that would shape the genre, but when you look at it as a standalone title, there&rsquo;s not all that much there.</p>

<p>This isn&rsquo;t meant to be a knock at the game. I had a great time playing through it, but that playthrough was only a few hours.</p>

<p>I used an emulator to do this, so most of my level grinding was done in fast-forward, so it felt even faster to get through this title.</p>

<p>If you&rsquo;re playing the &ldquo;classics&rdquo;, I&rsquo;d definitely recommend this title. Playing these early games gives you more of an appreciation for the later RPGs, as well as giving you a feel for how it all started.</p>

<p>Have you had a chance to play this title? How do you think it holds up nowadays, especially with the release of the mobile ports? Have any DQ memories you want to share? Let me know in the comments.</p>

<div id="galleria"><img src="http://www.alexbevi.com/images/dq1/dq1.000.png" data-title=" /images/dq1/dq1.000.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.001.png" data-title=" /images/dq1/dq1.001.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.002.png" data-title=" /images/dq1/dq1.002.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.003.png" data-title=" /images/dq1/dq1.003.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.004.png" data-title=" /images/dq1/dq1.004.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.005.png" data-title=" /images/dq1/dq1.005.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.006.png" data-title=" /images/dq1/dq1.006.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.007.png" data-title=" /images/dq1/dq1.007.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.008.png" data-title=" /images/dq1/dq1.008.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.009.png" data-title=" /images/dq1/dq1.009.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.010.png" data-title=" /images/dq1/dq1.010.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.011.png" data-title=" /images/dq1/dq1.011.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.012.png" data-title=" /images/dq1/dq1.012.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.013.png" data-title=" /images/dq1/dq1.013.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.014.png" data-title=" /images/dq1/dq1.014.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.015.png" data-title=" /images/dq1/dq1.015.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.016.png" data-title=" /images/dq1/dq1.016.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.017.png" data-title=" /images/dq1/dq1.017.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.018.png" data-title=" /images/dq1/dq1.018.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.019.png" data-title=" /images/dq1/dq1.019.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.020.png" data-title=" /images/dq1/dq1.020.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.021.png" data-title=" /images/dq1/dq1.021.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.022.png" data-title=" /images/dq1/dq1.022.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.023.png" data-title=" /images/dq1/dq1.023.png" /><img src="http://www.alexbevi.com/images/dq1/dq1.024.png" data-title=" /images/dq1/dq1.024.png" /></div>


<script>  Galleria.configure('transition', 'fade');  Galleria.run('#galleria');</script>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Just Gave Up On - Shadowrun (Genesis)]]></title>
        <link href="http://www.alexbevi.com/blog/2016/07/26/just-finished-shadowrun-genesis/"/>
        <updated>2016-07-26T05:25:39-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/07/26/just-finished-shadowrun-genesis</id>
        <content type="html"><![CDATA[<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.000.png"></p>

<p><strong>UPDATE: 2016-09-05</strong> - It was pointed out on <a href="https://www.reddit.com/r/rpg_gamers/comments/4uxq5n/just_gave_up_on_shadowrun_genesis">the Reddit thread</a> and in the comments below that I might have used a cheat which prevented finishing the game. I didn&rsquo;t think I&rsquo;d used one, but I think while doing research for the article i may have been testing it out :(</p>

<p>Note that you don&rsquo;t really need to cheat in this game to get more Nuyen; just grind ;)</p>

<p>Thanks to those who responded. It&rsquo;s worth noting that if you&rsquo;re going to play this game, <em>avoid the cheat menu</em> as it will bite you in the ass.</p>

<hr />

<p>As I work my way through the 8-bit and 16-bit games I grew up with, there are (and will continue to be) those that I just can&rsquo;t get through. <a href="https://en.wikipedia.org/wiki/Shadowrun_(1994_video_game)">Shadowrun</a> for the Sega Genesis turned out to be one of those titles.</p>

<p>I&rsquo;ve made it all the way to the final boss, and though he doesn&rsquo;t beat me, I empty all my clips (and my runner&rsquo;s clips) into him and just can&rsquo;t seem to kill him and trigger the endgame sequence.</p>

<p>This is extremely frustrating as I&rsquo;ve effectively finished this game, but if I can&rsquo;t beat the last boss I can&rsquo;t in good conscience call this a &ldquo;Just Finished&rdquo; article.</p>

<p>Regardless, I&rsquo;ve gone through enough of this game to be able to write about it, and based on my experience, recommend it to other players looking for some good retro cyberpunk action-RPG gaming.</p>

<!-- more -->


<p><img class="right" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.001.png"></p>

<p>This iteration of Shadowrun doesn&rsquo;t resemble the Super Nintendo&rsquo;s version of this title at all.</p>

<p>First off, you begin by selecting the type of player you want to run the game as: Samurai, Decker or Street Shaman. Each of these classes will give you different starting abilities and stats.</p>

<p>I chose to run as a Decker, as I wanted to get an idea as to how the matrix sequences differed between the games (plus I&rsquo;m a programmer and felt drawn to this class :P).</p>

<p>The story starts off with you at a hotel trying to track down some information about what happened to your brother. You interact with characters in this game through conversation trees (select A, B, C) in order to advance the story or get clues.</p>

<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.002.png"></p>

<p>A good chunk of the game is presented through these conversation views.</p>

<p>Once you leave the hotel, you start on your adventure into the world of Shadowrun.</p>

<p>Your character can walk around the initial city and go in and out of various buildings in order to trigger additional conversations with NPCs. It&rsquo;s a good idea to get a lay of the land as you&rsquo;ll be visiting each of these building repeatedly once you start shadowrunning, so it&rsquo;s worth taking the time to explore.</p>

<p>Some buildings will warn you that they contain ghouls. These buildings are where you can go to do some level grinding, or if you&rsquo;re on a run that has you clearing out ghouls, earn some money.</p>

<p><img class="right" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.006.png"></p>

<p>To level grind, you&rsquo;ll just be earning karma points which can be applied to the various stats your character has. These stats affect your weapons skills, magic skills, tech/computer skills or your aptitude with various weapon classes.</p>

<p>Although I started out as a Decker, I found myself maxing out my weapon skills early on to make the game a lot easier to progress through. It turns out there really isn&rsquo;t any demand for low level Deckers, so I didn&rsquo;t really have an opportunity to do any Matrix runs until much later in the game.</p>

<p>On the subject of shadowruns, the way you earn money (nuyen) in this game is by taking on various jobs (runs) from Mr. Johnson&rsquo;s. There are one or more Mr. Johnson&rsquo;s in each city you visit and they offer you work. Initially the types of work are either &ldquo;escort <name> to <location>&rdquo;, &ldquo;take package to <location>&rdquo; or &ldquo;clear out ghouls from abandoned building&rdquo;.</p>

<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.011.png"></p>

<p>I found that the easiest runs to make money at early on where the ghoul runs. You basically just go into the building, find some ghouls and start running in circles. They&rsquo;ll just follow you so you can pick them off one at a time.</p>

<p>Although this became tedious pretty quickly, you get money and karma and can level up your weapon stats in order to make repeating this easier.</p>

<p>The escort runs are easy, and if you took the time to get an idea where each target is, it&rsquo;s even easier to do. It just takes time and the payout isn&rsquo;t that great.</p>

<p>Eventually you&rsquo;ll earn enough money to buy some info about where to go next and you have the opportunity to travel to a new city.</p>

<p>There are a handful of cities you can visit in this game, and each one offers it&rsquo;s own set of challenges, as well as opportunities for more advanced runs.</p>

<p>You&rsquo;ll also meet other shadowrunners in bars and clubs throughout the game. These runners will give you more information about shadowrunning, the story, as well as background about the Shadowrun world.</p>

<p>These characters can also be hired to assist you on your runs. Each one has two rates; a single run rate or a lifetime rate.</p>

<p>I found I didn&rsquo;t really hire anyone until I hit the endgame as I didn&rsquo;t really need the help. If you&rsquo;re playing through the game as a shaman or samurai and don&rsquo;t bother upgrading your computer skills, it may be easier to hire a good decker than to upgrade your own stats and get a cyberdeck.</p>

<p><img class="right" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.009.png"></p>

<p>You&rsquo;ll meet new Mr. Johnson&rsquo;s who offer more difficult missions that involve traveling between the various cities in order to do more difficult quests such as infiltrating corporations to either steal secrets or extract employees, or running the matrix.</p>

<p>Both of these advanced run types offer their own challenges and require abilities to be leveled up in order to proceed.</p>

<p>When infiltrating corporations, you&rsquo;ll need to be able to have electronics skills in order to be able to break maglocks, and you&rsquo;ll want your weapon skills upgraded so as to be able to shoot guards without attracting more.</p>

<p>The infiltration jobs have you going through multiple floors of these buildings, with each floor having guards to deal with, security cameras to avoid and wall safes to plunder.</p>

<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.015.png"></p>

<p>It helps to have computer skills when doing these runs as you can hack the computers to disable cameras, turn off alarms and open doors.</p>

<p>This takes us to decking and matrix running.</p>

<p>Unlike the SNES version of this game, the Genesis version actually has a bit more depth to the matrix.</p>

<p>You&rsquo;ll need to have computer skills first, then also have computer software for fighting with subsystems and identifying and avoiding various threats.</p>

<p>The fighting itself is pretty repetitive, but the concept is fun.</p>

<p>There are various types of components within a matrix system. You have to hack each of these as you move deeper into the system. The end goal is usually to hit a data store and download or delete a file.</p>

<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.021.png"></p>

<p>One way to easily earn money is to hack into a system, download the maximum number of data files then try to sell them to a contact in [city]. Near the end of the game i was able to get upwards of 10K for some files, which made upgrading my equipment a lot easier to do ;)</p>

<p>Although I&rsquo;ve been a huge fan of the SNES version of this game since I was a kid, I think I may have enjoyed the Genesis incarnation more. The music wasn&rsquo;t nearly as good, but the story was well laid out, there were a lot of options on how to progress and it didn&rsquo;t feel nearly as linear.</p>

<p>The addition of the classes gave you a sense of depth and replay-ability, though chances are you could just max out all stats for any player type and have same experience no matter how you started the game.</p>

<p>I also really enjoyed the shadowrunning aspect of this game. In the SNES version you could hire runners to help you get through the game, but you didn&rsquo;t actually participate in shadowruns for profit.</p>

<p>If you haven&rsquo;t given this game a shot, I would highly recommend it. It turned out to be a lot of fun, and an excellent addition to the limited field of cyberpunk games out there.</p>

<p>If you have any recommendations for other games in this genre I should check out, or if you want to share your opinion on this or the SNES title, please feel free to leave me a comment.</p>

<div id="galleria"><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.003.png" data-title="/images/shadowrun-gens/shadowrun.003.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.004.png" data-title="/images/shadowrun-gens/shadowrun.004.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.005.png" data-title="/images/shadowrun-gens/shadowrun.005.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.007.png" data-title="/images/shadowrun-gens/shadowrun.007.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.008.png" data-title="/images/shadowrun-gens/shadowrun.008.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.010.png" data-title="/images/shadowrun-gens/shadowrun.010.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.012.png" data-title="/images/shadowrun-gens/shadowrun.012.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.013.png" data-title="/images/shadowrun-gens/shadowrun.013.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.014.png" data-title="/images/shadowrun-gens/shadowrun.014.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.015.png" data-title="/images/shadowrun-gens/shadowrun.015.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.016.png" data-title="/images/shadowrun-gens/shadowrun.016.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.017.png" data-title="/images/shadowrun-gens/shadowrun.017.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.018.png" data-title="/images/shadowrun-gens/shadowrun.018.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.019.png" data-title="/images/shadowrun-gens/shadowrun.019.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.020.png" data-title="/images/shadowrun-gens/shadowrun.020.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.022.png" data-title="/images/shadowrun-gens/shadowrun.022.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.023.png" data-title="/images/shadowrun-gens/shadowrun.023.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.024.png" data-title="/images/shadowrun-gens/shadowrun.024.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.025.png" data-title="/images/shadowrun-gens/shadowrun.025.png" /><img src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.026.png" data-title="/images/shadowrun-gens/shadowrun.026.png" /></div>


<script>  Galleria.configure('transition', 'fade');  Galleria.run('#galleria');</script>

]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Extracting Best ROM from GoodTools Generated ROM Sets]]></title>
        <link href="http://www.alexbevi.com/blog/2016/07/25/extracting-best-rom-from-goodtools-generated-rom-sets/"/>
        <updated>2016-07-25T15:17:38-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/07/25/extracting-best-rom-from-goodtools-generated-rom-sets</id>
        <content type="html"><![CDATA[<p>As a kid of the 80&rsquo;s, I have fond memories of all the old 8-bit and 16-bit consoles that I grew up with.</p>

<p>Although it&rsquo;s easy enough to find ROMs, I tend to find myself going for the <a href="https://en.wikipedia.org/wiki/GoodTools">GoodTools</a> generated sets more often than not as they&rsquo;re considered &ldquo;complete&rdquo;.</p>

<p>This is kind of ridiculous as I don&rsquo;t speak Japanese, which constitutes the vast majority of the contents of these sets.</p>

<p>Even though most emulators support compressed ROM sets, I&rsquo;d prefer to just have the English ROMs available on their own in one place.</p>

<p>As a programmer, I thought &ldquo;How can I do this in Linux?&rdquo;, but more specifically, &ldquo;how do I do this from the command line directly?&rdquo;.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># extract best rom to directory
</span><span class='line'># best contains !
</span><span class='line'>7z e "*.7z" -o../../ *[!]*.* -r
</span><span class='line'>
</span><span class='line'># purge all non US/European
</span><span class='line'>find . -type f ! -name '*(U)*' ! -name '*(E)*' -delete
</span><span class='line'>
</span><span class='line'># purge duplicates where a (U) exists alongiside an (E)
</span><span class='line'>for f in *"(E)"*; do us=`echo $f | sed -r 's/\(E\)+/\(U\)/g'`; if [ -e "$us" ]; then echo "FOUND $us - removing $f"; rm "$f"; fi; done</span></code></pre></td></tr></table></div></figure>


<p>If you find yourself with compressed ROM sets and you want to just grab the English ones, this might just come in handy ;)</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Redmine Knowledgebase 3.2.0 Released]]></title>
        <link href="http://www.alexbevi.com/blog/2016/06/22/redmine-knowledgebase-3-dot-2-released/"/>
        <updated>2016-06-22T21:33:34-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/06/22/redmine-knowledgebase-3-dot-2-released</id>
        <content type="html"><![CDATA[<p>I haven&rsquo;t been very actively involved with this plugin or the Redmine community as a whole lately, but it would seem there is a very active user-base still logging bugs and enhancing this project.</p>

<p>You can grab a copy of the release <a href="https://github.com/alexbevi/redmine_knowledgebase/releases/tag/v3.2.0">on GitHub</a>.</p>

<p>I&rsquo;m pushing out version 3.2.0 of the plugin thanks to the efforts of some very dedicated community members, who I&rsquo;d like to highlight below:</p>

<p>Thanks to Frederico Camara:</p>

<ul>
<li>updating acts_as_rated to work with Redmine 3.2.x</li>
</ul>


<p>Thanks to Eduard Kuleshov:</p>

<ul>
<li>getting this plugin supported in Redmine 3.0.x</li>
</ul>


<p>Thanks to Axel Kämpfe:</p>

<ul>
<li>getting this plugin supported in Redmine 3.1.x and 3.2.x</li>
</ul>


<p>HUGE thanks to Rob Spearman for basically taking over the project and pushing it forward:</p>

<h2>New Configuaration options</h2>

<ul>
<li>Show articles without tabs</li>
<li>Show attachments before article content</li>
<li>Show thumbnails for articles in lists</li>
<li>Show breadcrumbs for articles in lists</li>
</ul>


<h2>New permissions</h2>

<ul>
<li>Article history will only show up if have view permission</li>
<li>optional permission for users to manage just their own articles. (#306)</li>
</ul>


<h2>Layout</h2>

<ul>
<li>Sort Tags on the index page</li>
<li>Added authored view so users can find articles by author easily</li>
</ul>


<!-- more -->


<h2>Bug Fixes</h2>

<ul>
<li>article view counts not updating (#304)</li>
<li>top rated list not valid (#305)</li>
<li>ActiveRecord::StaleObjectError (Attempted to destroy a stale object: KbArticle) (#300)</li>
<li>Error when generating a PDF of an article with pictures (#308)</li>
<li>500 Internal Server Error - if DELETE category but it&rsquo;s have subcategory (#293)</li>
</ul>


<p>Note that this is a preliminary release as there is one bug in here that I haven&rsquo;t squashed.</p>

<p>When trying to search, you&rsquo;re prompted with a failure similar to:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Started GET "/search?utf8=%E2%9C%93&q=stuff" for 127.0.0.1 at 2016-06-23 01:14:06 +0000
</span><span class='line'>Processing by SearchController#index as HTML
</span><span class='line'>  Parameters: {"utf8"=&gt;"✓", "q"=&gt;"stuff"}
</span><span class='line'>  Current user: admin (id=1)
</span><span class='line'>Completed 500 Internal Server Error in 632ms (ActiveRecord: 173.6ms)
</span><span class='line'>
</span><span class='line'>NoMethodError (undefined method `where' for #&lt;Hash:0x000000096b0d60&gt;):
</span><span class='line'>  lib/plugins/acts_as_searchable/lib/acts_as_searchable.rb:93:in `search_result_ranks_and_ids'
</span><span class='line'>  lib/redmine/search.rb:127:in `block in load_result_ids'
</span><span class='line'>  lib/redmine/search.rb:125:in `each'
</span><span class='line'>  lib/redmine/search.rb:125:in `load_result_ids'
</span><span class='line'>  lib/redmine/search.rb:115:in `block in load_result_ids_from_cache'
</span><span class='line'>  lib/redmine/search.rb:114:in `load_result_ids_from_cache'
</span><span class='line'>  lib/redmine/search.rb:99:in `result_ids'
</span><span class='line'>  lib/redmine/search.rb:70:in `result_count'
</span><span class='line'>  app/controllers/search_controller.rb:65:in `index'
</span><span class='line'>  lib/redmine/sudo_mode.rb:63:in `sudo_mode'</span></code></pre></td></tr></table></div></figure>


<p>I&rsquo;m pretty sure this has to do with how we&rsquo;re setting up <code>acts_as_searchable</code> in the <code>kb_article</code> model. Any suggestions welcome ;)</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[What's Up - May/June 2016]]></title>
        <link href="http://www.alexbevi.com/blog/2016/06/14/whats-up-may-slash-june-2016/"/>
        <updated>2016-06-14T20:38:02-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/06/14/whats-up-may-slash-june-2016</id>
        <content type="html"><![CDATA[<p>It&rsquo;s been a while since I posted the <a href="http://www.alexbevi.com/blog/2016/04/19/just-finished-seiken-densetsu-3/">Seiken Densetsu 3</a> review, so I figured as it might be a while before I get around to posting more content, I&rsquo;ll just throw up a quick update.</p>

<h2>Gaming</h2>

<p><img class="left" src="http://www.alexbevi.com/images/shadowrun-gens/shadowrun.015.png"></p>

<p>I&rsquo;m currently working my way through three games. After finishing the <a href="http://www.alexbevi.com/blog/2016/02/23/just-finished-shadowrun/">Shadowrun</a> play-through for SNES, I got some good feedback about the <a href="https://en.wikipedia.org/wiki/Shadowrun_(1994_video_game)">Genesis version</a>. I decided to give that a go, and I&rsquo;ve currently made it to the last boss, but am having no luck beating him.</p>

<p>I&rsquo;m pretty sure I&rsquo;m going to have to save up some nuyen and grind it out with some better runners in order to be able to beat Thon. This is a bit of a pain in the ass, and is the reason I ended up abandoning <a href="http://www.alexbevi.com/blog/2015/01/16/just-finished-terranigma/">Terranigma</a> previously.</p>

<p>I really enjoyed that game, but since I&rsquo;ve got very limited time decided to move on to the next challenge.</p>

<p>By challenge, I meant <em>CHALLENGE</em>. I decided to give <a href="https://en.wikipedia.org/wiki/The_7th_Saga">The 7th Saga</a> another shot, and have now officially made it MUCH further than I ever have before.</p>

<!-- more -->


<p><img class="right" src="http://www.alexbevi.com/images/7th-saga/7th-saga.009.png"></p>

<p>This game was alway brutally hard for me when I was a kid, and it still is. You&rsquo;ve got limited inventory for healing items, everything is expensive and the enemies are generally overpowered.</p>

<p>On top of that, it takes forever to level up, and when you do it doesn&rsquo;t really make all that much of a difference.</p>

<p>I&rsquo;ve made it as far as <a href="http://mikesrpgcenter.com/7thsaga/maps/telaine.html">Telaine</a> and have the Wind, Water and Star runes. Still a ways to go, but I don&rsquo;t know that I&rsquo;ll continue &hellip;</p>

<p>Finally, since I haven&rsquo;t played through this since the late &lsquo;80s, I&rsquo;m diving back into <a href="https://en.wikipedia.org/wiki/Dragon_Quest_(video_game)">Dragon Quest</a>. I&rsquo;m going to be playing through the fan-translated SNES port, which I think is the superior port (I don&rsquo;t like the mobile remakes of these games &hellip;).</p>

<p>I think I should have this one done relatively soon as it&rsquo;s not a very long game, and although it&rsquo;s a bit grind-heavy, I&rsquo;ve got 8x fast-forward on my emulator :P</p>

<h2>Anime</h2>

<p>Just a quick update on the series I&rsquo;ve burned through recently.</p>

<p><strong><a href="http://myanimelist.net/anime/17265/Log_Horizon">Log Horizon</a> - Season 1</strong></p>

<p>This reminded me or SAO a bit, but with a lot less &ldquo;Asuna! Kirito! <repeat>&rdquo;, and a lot more &ldquo;Lens flare from glasses&rdquo; and &ldquo;Pushing glasses back into place&rdquo;.</p>

<p>Story was enjoyable. Characters were interesting. I&rsquo;d recommend it.</p>

<p><strong><a href="http://myanimelist.net/anime/2025/Darker_than_Black__Kuro_no_Keiyakusha">Darker than Black</a> - Season 1+2</strong></p>

<p>REALLY enjoyed this. Good action. Interesting plot. Good dialog. I&rsquo;d recommend it.</p>

<p><strong><a href="http://myanimelist.net/anime/30276/One_Punch_Man">One Punch Man</a> - Season 1</strong></p>

<p>I LOVE this. Saitama is OP AF!!! The story is a bit goofy, but the characters are interesting and the plot keeps you interested. Would totally recommend this.</p>

<p>I think that&rsquo;s all for now.</p>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Just Finished - Seiken Densetsu 3]]></title>
        <link href="http://www.alexbevi.com/blog/2016/04/19/just-finished-seiken-densetsu-3/"/>
        <updated>2016-04-19T14:30:20-04:00</updated>
        <id>http://www.alexbevi.com/blog/2016/04/19/just-finished-seiken-densetsu-3</id>
        <content type="html"><![CDATA[<p><img class="left" src="http://www.alexbevi.com/images/sd3/sd3.026.png"></p>

<p><a href="https://en.wikipedia.org/wiki/Seiken_Densetsu_3">Seiken Densetsu 3 (聖剣伝説3)</a> is the third installment in the <a href="https://en.wikipedia.org/wiki/Mana_(series)">Mana series</a>. It&rsquo;s the sequel to <a href="https://en.wikipedia.org/wiki/Secret_of_Mana">Secret of Mana</a>, which is the entry into the series that most North American gamers would be familiar with.</p>

<p>Once again, I played through this game on my phone using the fantastic <a href="http://www.explusalpha.com/home/snes9x-ex">Snes9x EX</a>. Please support this dev as he provides a fantastic product. For some reason though, most of the screenshots I took came out stretched. This hasn&rsquo;t happened before, and I&rsquo;ve been playing a couple other games that this isn&rsquo;t happening for either, so I&rsquo;ll chalk this up to bad luck :|</p>

<p><img src="http://www.alexbevi.com/images/sd3/sd3.005.png"></p>

<p><em>NOTE</em> I ran these screenshots through <a href="http://pmt.sourceforge.net/pngcrush/">pngcrush</a> (<code>ls *.png | while read line; do pngcrush -ow -brute $line; done</code>) to get the size down a bit ;)</p>

<p>I&rsquo;m leaving these images in here as they were part of my &ldquo;journey&rdquo;, though hopefully they don&rsquo;t deter anyone from playing this game, as the game is <em>fantastic</em>.</p>

<p>First off, if you&rsquo;re a fan of <a href="https://en.wikipedia.org/wiki/Secret_of_Mana">Secret of Mana</a>, the initial &ldquo;feel&rdquo; of the game will be familiar, as will the art style and sound.</p>

<!-- more -->


<p>Whereas SoM had you gradually encounter the two other playable characters at set points in the game, SD3 has you selecting your 3 main characters before you even begin.</p>

<p>I decided to go with Duran, Carlie and Kevin (something about a werewolf named Kevin made me chuckle :P). Duran&rsquo;s story starts off with the castle where he lives being invaded by a wizard who almost kills him. The wizard lets Duran live, so naturally Duran has to set off on a quest to find and defeat the wizard.</p>

<p><img src="http://www.alexbevi.com/images/sd3/sd3.004.png"></p>

<p>On this journey, he&rsquo;ll run into the other characters I selected (Kevin and Carlie), and each of their stories will mix into Duran&rsquo;s. This is actually a really cool element of this game as it gives it a lot of replay value. No matter what combination of characters you pick, their stories will all overlap. Also, you&rsquo;ll run into all the other characters you didn&rsquo;t pick, so every character makes an appearance throughout the game.</p>

<p><img class="right" src="http://www.alexbevi.com/images/sd3/sd3.010.png"></p>

<p>You travel around the game mostly on foot initially, but eventually new methods of travel will open up. As with SoM, you can get to certain areas via Cannon Travel (though there&rsquo;s a couple of fetch-quests before you can actually take advantage of this). There&rsquo;s also a ship, a weird turtle thing, and eventually Flammie the dragon.</p>

<p>The combat system is reminiscent of SoM as well, though this time around it feels a lot more &ldquo;button mash-ey&rdquo;. I found that I just spammed the B button throughout most of this game and didn&rsquo;t really use any strategy during combat; aside from healing periodically.</p>

<p><img class="left" src="http://www.alexbevi.com/images/sd3/sd3.014.png"></p>

<p>You get experience by killing enemies, which will allow you to level up your characters. Leveling up lets you increase various stats, that should make your characters perform better in future battles.</p>

<p>As you make your way through the game, you&rsquo;ll start finding these pillars that are guarded by stronger enemies. These are the Mana stones, and apparently contain God-beasts that will be awakened if you shatter the stones.</p>

<p>These stones can also be used to change your character&rsquo;s class. This is another cool aspect of this game, as it give the leveling system a bit more flavour. You can change classes twice in this game; once at level 18, and again at level 38. Each of these classes is aligned with either &ldquo;Light&rdquo; or &ldquo;Dark&rdquo;, and gives the character new skills/improvements.</p>

<p><img src="http://www.alexbevi.com/images/sd3/sd3.017.png"></p>

<p>The game can feel a bit &ldquo;grindy&rdquo; due to the need to constantly trudge back and forth between areas, and there are enemies on each screen. These battles are all avoidable, but you&rsquo;ll want to level up for the boss fights, and eventually the God Beasts.</p>

<p>While you&rsquo;re trekking though, you get to enjoy some really good background music. If you like Secret of Mana, you&rsquo;ll love Seiken Densetsu 3. You can have a listen over at <a href="https://www.youtube.com/watch?v=qrywwZ7oL2w&amp;index=30&amp;list=PL4649F0DBF0FC09E3">YouTube</a> to get an idea what&rsquo;s in store for you ;)</p>

<p><img class="right" src="http://www.alexbevi.com/images/sd3/sd3.031.png"></p>

<p>The artwork is also top notch. It&rsquo;s really a shame this game never made it to North America as this is possibly one of the best looking SNES games out there. The background design, character design and monster sprites are all very, very well done. There is a lot of variety to the various regions of the world.</p>

<p>Once you&rsquo;ve shattered all the Mana stones, you unleash the God Beasts. Their position is shown on the world map, and they can be fought in any order, but it&rsquo;s a good idea to start from the top left of the map and work your way through them sequentially.</p>

<p>I learned this the hard way as I only play this game on occasion, and ended up forgetting where I was. This resulted in A LOT of backtracking to find the last couple of beasts.</p>

<p>I thoroughly enjoyed playing this game and would highly recommend this to anyone out there that likes JRPGs, action RPGs and 8/16-bit gaming in general. The graphics, music and gameplay are all very well done, and the story lines are interesting, even if there is occasionally some cheesy dialog :P</p>

<div id="galleria"><img src="http://www.alexbevi.com/images/sd3/sd3.000.png" data-title="/images/sd3/sd3.000.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.001.png" data-title="/images/sd3/sd3.001.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.002.png" data-title="/images/sd3/sd3.002.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.003.png" data-title="/images/sd3/sd3.003.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.006.png" data-title="/images/sd3/sd3.006.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.007.png" data-title="/images/sd3/sd3.007.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.008.png" data-title="/images/sd3/sd3.008.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.011.png" data-title="/images/sd3/sd3.011.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.012.png" data-title="/images/sd3/sd3.012.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.013.png" data-title="/images/sd3/sd3.013.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.015.png" data-title="/images/sd3/sd3.015.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.016.png" data-title="/images/sd3/sd3.016.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.018.png" data-title="/images/sd3/sd3.018.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.019.png" data-title="/images/sd3/sd3.019.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.020.png" data-title="/images/sd3/sd3.020.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.021.png" data-title="/images/sd3/sd3.021.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.022.png" data-title="/images/sd3/sd3.022.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.023.png" data-title="/images/sd3/sd3.023.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.024.png" data-title="/images/sd3/sd3.024.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.025.png" data-title="/images/sd3/sd3.025.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.027.png" data-title="/images/sd3/sd3.027.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.028.png" data-title="/images/sd3/sd3.028.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.029.png" data-title="/images/sd3/sd3.029.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.030.png" data-title="/images/sd3/sd3.030.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.032.png" data-title="/images/sd3/sd3.032.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.033.png" data-title="/images/sd3/sd3.033.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.034.png" data-title="/images/sd3/sd3.034.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.035.png" data-title="/images/sd3/sd3.035.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.036.png" data-title="/images/sd3/sd3.036.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.037.png" data-title="/images/sd3/sd3.037.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.038.png" data-title="/images/sd3/sd3.038.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.039.png" data-title="/images/sd3/sd3.039.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.040.png" data-title="/images/sd3/sd3.040.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.041.png" data-title="/images/sd3/sd3.041.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.042.png" data-title="/images/sd3/sd3.042.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.043.png" data-title="/images/sd3/sd3.043.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.044.png" data-title="/images/sd3/sd3.044.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.045.png" data-title="/images/sd3/sd3.045.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.046.png" data-title="/images/sd3/sd3.046.png" /><img src="http://www.alexbevi.com/images/sd3/sd3.047.png" data-title="/images/sd3/sd3.047.png" /></div>


<script>  Galleria.configure('transition', 'fade');  Galleria.run('#galleria');</script>


<p>I finished this game over a month ago, so I&rsquo;m still pretty slow cranking out these reviews &hellip;</p>

<p>I&rsquo;m currently working my way through <a href="https://en.wikipedia.org/wiki/The_7th_Saga">The 7th Saga</a> for SNES since I clearly need <em>more</em> pain and frustration in my life :P When that game is annoying me, I&rsquo;m also working on Sega Genesis version of <a href="https://en.wikipedia.org/wiki/Shadowrun_(1994_video_game)">Shadowrun</a>.</p>

<p>That game was recommended by some of my readers on Reddit so I figured I had to give it a whirl. So far I&rsquo;m actually really enjoying it, and it is VERY different the the SNES game of the same name.</p>

<p>Hopefully I&rsquo;ll have more for you in the near(er) future :)</p>
]]></content>
    </entry>
    
</feed>
