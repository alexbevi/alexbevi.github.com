<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[Category: mongodb | ALEX BEVILACQUA]]></title>
    <link href="http://www.alexbevi.com/blog/categories/mongodb/atom.xml" rel="self"/>
    <link href="http://www.alexbevi.com/"/>
    <updated>2020-01-27T04:54:05-05:00</updated>
    <id>http://www.alexbevi.com/</id>
    <author>
        <name><![CDATA[Alex Bevilacqua]]></name>
        <email><![CDATA[alex@alexbevi.com]]></email>
      </author>
    <generator uri="http://octopress.org/">Octopress</generator>

    
    <entry>
        <title type="html"><![CDATA[What is MongoDB FTDC (aka. diagnostic.data)]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/26/what-is-mongodb-ftdc-aka-diagnostic-dot-data/"/>
        <updated>2020-01-26T18:14:50-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/26/what-is-mongodb-ftdc-aka-diagnostic-dot-data</id>
        <content type="html"><![CDATA[# What is MongoDB FTDC (aka. `diagnostic.data`)

[Full Time Diagnostic Data Capture (FTDC)](https://docs.mongodb.com/manual/administration/analyzing-mongodb-performance/#full-time-diagnostic-data-capture) was introduced in MongoDB 3.2 (via [SERVER-19585](https://jira.mongodb.org/browse/SERVER-19585)), to incrementally collect the results of certain diagnostic commands to assist MongoDB support with troubleshooting issues.

On log rotation or startup, a `mongod` or `mongos` will collect and log:

- [`getCmdLineOpts`](https://docs.mongodb.com/manual/reference/command/getCmdLineOpts/): `db.adminCommand({getCmdLineOpts: true})`
- [`buildInfo`](https://docs.mongodb.com/manual/reference/command/buildInfo/): `db.adminCommand({buildInfo: true})`
- [`hostInfo`](https://docs.mongodb.com/manual/reference/command/hostInfo/): `db.adminCommand({hostInfo: true})`

As configured by [`diagnosticDataCollectionPeriodMillis`](https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionPeriodMillis) and defaulting to every 1 second, FTDC will collect to output of the following commands:

- [`serverStatus`](https://docs.mongodb.com/manual/reference/command/serverStatus/): `db.serverStatus({tcmalloc: true})`
- [`replSetGetStatus`](https://docs.mongodb.com/manual/reference/command/replSetGetStatus/): `rs.status()`
- [`collStats`](https://docs.mongodb.com/manual/reference/command/collStats/) for the [`local.oplog.rs`](https://docs.mongodb.com/manual/reference/local-database/#local.oplog.rs) collection ([mongod](https://docs.mongodb.com/manual/reference/program/mongod/#bin.mongod) only)
- [`connPoolStats`](https://docs.mongodb.com/manual/reference/command/connPoolStats/#dbcmd.connPoolStats) ([mongos](https://docs.mongodb.com/manual/reference/program/mongos/#bin.mongos) only)

When FTDC is enabled (per [`diagnosticDataCollectionEnabled`](https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionEnabled)), the `metrics.xxxxxxx` files will be stored in [`diagnosticDataCollectionDirectoryPath`](https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionDirectoryPath) which by default is the _diagnostic.data_ directory within the [`systemLog.path`](https://docs.mongodb.com/manual/reference/configuration-options/#systemLog.path).

With [SERVER-21818](https://jira.mongodb.org/browse/SERVER-21818) (introduced in MongoDB 3.2.13) and [SERVER-31400](https://jira.mongodb.org/browse/SERVER-31400) (introduced in MongoDB 3.4.16) the diagnostic data capture scope was broadened to not only include internal diagnostic commands but system metrics as well. Depending on the host operating system, the diagnostic data may include one or more of the following statistics:

- CPU utilization (ex: [`/proc/stat`](http://www.linuxhowtos.org/System/procstat.htm))
- Memory utilization (ex: [`/proc/meminfo`](https://www.thegeekdiary.com/understanding-proc-meminfo-file-analyzing-memory-utilization-in-linux/))
- Disk utilization related to performance (ex: [`*/sys/block/\*/stat*`](https://www.kernel.org/doc/Documentation/block/stat.txt))
- Network performance statistics ([`/proc/net/netstat`](https://unix.stackexchange.com/questions/435579/is-there-documentation-for-proc-net-netstat-and-proc-net-snmp))

The `metrics.xxxxxxx` files in the `diagnostic.data` directory contain only statistics about the performance of the system and the database. They are stored in a compressed format, and are not human-readable.

Just a quick note regarding privacy, regardless of the version, the data in _diagnostic.data_ never contains:

- Samples of queries, query predicates, or query results
- Data sampled from any end-user collection or index
- System or MongoDB user credentials or security certificates

FTDC data contains certain host machine information such as hostnames, operating system information, and the options or settings used to start the `mongod` or `mongos`. This information may be considered protected or confidential by some organizations or regulatory bodies, but is not typically considered to be [Personally Identifiable Information (PII)](https://en.wikipedia.org/wiki/Personal_data).

If you want to have a closer look at the diagnostic data collection process, you can inspect the [FTDC code](https://github.com/mongodb/mongo/tree/master/src/mongo/db/ftdc).

## FTDC Structure

<!-- MORE -->

There are two types of FTDC documents: a [BSON metadata document](https://github.com/mongodb/mongo/blob/134a4083953270e8a11430395357fb70a29047ad/src/mongo/db/ftdc/util.h#L136), or a [BSON metric chunk](https://github.com/mongodb/mongo/blob/134a4083953270e8a11430395357fb70a29047ad/src/mongo/db/ftdc/util.h#L150).

Each document is made up of an `_id`, a `type` and either a `doc` or `data` field. The `type` field is used to identify the document type:

- 0: Metadata Document
- 1: Metric Chunk

The `doc` or `data` fields will contain "samples" in the form of:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span> <span class="c1">// Time at which all collecting started</span>
</span><span class='line'>  <span class="s2">&quot;name&quot;</span> <span class="o">:</span> <span class="c1">// name is from name() in FTDCCollectorInterface</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>        <span class="s2">&quot;start&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span> <span class="c1">// Time at which name() collection started</span>
</span><span class='line'>        <span class="s2">&quot;data&quot;</span> <span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">}</span>  <span class="c1">// data comes from collect() in FTDCCollectorInterface</span>
</span><span class='line'>        <span class="s2">&quot;end&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>  <span class="c1">// Time at which name() collection ended</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="p">...</span> <span class="c1">// more than 1 collector be sampled</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span> <span class="o">:</span> <span class="nx">DateTime</span> <span class="c1">// Time at which all collecting ended</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

Samples are [collected by `FTDCCollectorInterface`](https://github.com/mongodb/mongo/blob/f922827d45ce752e148185dfa3a785f7c9cf29fd/src/mongo/db/ftdc/collector.h#L110) instances.

### Metadata Document

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;_id&quot;</span><span class="o">:</span>  <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;type&quot;</span><span class="o">:</span> <span class="mi">0</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;doc&quot;</span><span class="o">:</span>  <span class="nb">Object</span><span class="o">&lt;</span><span class="nx">Sample</span><span class="o">&gt;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

On log rotation or startup, the first FTDC entry will be collected and stored. This is a BSON document that contains information sampled by running [`getCmdLineOpts`](https://docs.mongodb.com/manual/reference/command/getCmdLineOpts/), [`buildInfo`](https://docs.mongodb.com/manual/reference/command/buildInfo/) and [`hostInfo`](https://docs.mongodb.com/manual/reference/command/hostInfo/).

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// example</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span><span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;buildInfo&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;getCmdLineOpts&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;hostInfo&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span><span class="o">:</span> <span class="nx">DateTime</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

This sample will be stored in the `doc` field of the metadata document.

### Metric Chunk

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;_id&quot;</span><span class="o">:</span>  <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;type&quot;</span><span class="o">:</span> <span class="mi">1</span>
</span><span class='line'>  <span class="s2">&quot;data&quot;</span><span class="o">:</span> <span class="nx">BinData</span><span class="p">(...)</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

During each collection interval (as configured by [`diagnosticDataCollectionPeriodMillis`](https://docs.mongodb.com/manual/reference/parameters/index.html#param.diagnosticDataCollectionPeriodMillis)), a metric chunk will be created and a sample will be collected, compressed and stored to the `data` document as Binary Data.

This sample can contain the results of internal commands such as [`serverStatus`](https://docs.mongodb.com/manual/reference/command/serverStatus/),[`replSetGetStatus`](https://docs.mongodb.com/manual/reference/command/replSetGetStatus/), [`collStats`](https://docs.mongodb.com/manual/reference/command/collStats/) for the [`local.oplog.rs`](https://docs.mongodb.com/manual/reference/local-database/#local.oplog.rs) collection or [`connPoolStats`](https://docs.mongodb.com/manual/reference/command/connPoolStats/#dbcmd.connPoolStats), as well as external system metrics.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// example</span>
</span><span class='line'><span class="p">{</span>
</span><span class='line'>  <span class="s2">&quot;start&quot;</span><span class="o">:</span> <span class="nx">DateTime</span><span class="p">,</span>
</span><span class='line'>  <span class="s2">&quot;serverStatus&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;connPoolStats&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;systemMetrics&quot;</span><span class="o">:</span> <span class="p">{</span> <span class="p">...</span> <span class="p">},</span>
</span><span class='line'>  <span class="s2">&quot;end&quot;</span><span class="o">:</span> <span class="nx">DateTime</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

## Working with FTDC

FTDC files, such as the `metrics.2019-10-28T19-02-23Z-00000` sample we'll be working with below are just [BSON](http://bsonspec.org/) files. As such, the [`bsondump`](https://docs.mongodb.com/manual/reference/program/bsondump/) utility can be used to inspect the contents:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">METRICS</span><span class="o">=</span><span class="nx">metrics</span><span class="p">.</span><span class="mi">2019</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="mi">28</span><span class="nx">T19</span><span class="o">-</span><span class="mi">02</span><span class="o">-</span><span class="mi">23</span><span class="nx">Z</span><span class="o">-</span><span class="mi">00000</span>
</span><span class='line'><span class="nx">bsondump</span> <span class="o">--</span><span class="nx">quiet</span> <span class="nx">$METRICS</span> <span class="o">|</span> <span class="nx">less</span>
</span></code></pre></td></tr></table></div></figure>

<img src="/images/ftdc-001.png">

`bsondump` will default to emitting JSON, so we can interact with this using the [`jq`]() utility. For example, if we only want to review the _Metadata Document_ this could be done as follows:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># bsondump &lt; 4.0</span>
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> jq -s <span class="s1">&#39;.[] | select( .type == 0)&#39;</span> <span class="p">|</span> less
</span><span class='line'>
</span><span class='line'><span class="c"># bsondump &gt;= 4.0</span>
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> jq -s <span class="s1">&#39;.[] | select( .type | .&quot;$numberInt&quot; == &quot;0&quot;)&#39;</span> <span class="p">|</span> less
</span></code></pre></td></tr></table></div></figure>

<img src="/images/ftdc-002.png">

Working with _Metric Chunks_ is a little more complicated as they are actually zlib compressed BSON documents.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># bsondump &lt; 4.0</span>
</span><span class='line'><span class="nv">METRICS</span><span class="o">=</span>metrics.2019-12-20T14-22-56Z-00000
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;.[] | select( .type == 1)&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;first | .data .&quot;$binary&quot;&#39;</span> -Mc <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  ruby -rzlib -rbase64 -e <span class="s1">&#39;d = STDIN.read; print Zlib::Inflate.new.inflate(Base64.decode64(d)[4..-1])&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  bsondump --quiet
</span><span class='line'>
</span><span class='line'><span class="c"># bsondump &gt;= 4.0</span>
</span><span class='line'><span class="nv">METRICS</span><span class="o">=</span>metrics.2019-12-20T14-22-56Z-00000
</span><span class='line'>bsondump --quiet <span class="nv">$METRICS</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;.[] | select( .type | .&quot;$numberInt&quot; == &quot;1&quot;)&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  jq -s <span class="s1">&#39;first | .data .&quot;$binary&quot; .base64&#39;</span> -Mc <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  ruby -rzlib -rbase64 -e <span class="s1">&#39;d = STDIN.read; print Zlib::Inflate.new.inflate(Base64.decode64(d)[4..-1])&#39;</span> <span class="p">|</span> <span class="se">\</span>
</span><span class='line'>  bsondump --quiet
</span></code></pre></td></tr></table></div></figure>

You eagle-eyed Rubyists will notice that we're clipping the first 4 bytes from the binary data we're reading from STDIN. This is to drop the header before we try to decompress the stream.

If you don't do this [zlib](https://www.zlib.net/) will complain and fail:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>Traceback <span class="o">(</span>most recent call last<span class="o">)</span>:
</span><span class='line'>        1: from -e:1:in <span class="sb">`</span>&lt;main&gt;<span class="s1">&#39;</span>
</span><span class='line'><span class="s1">-e:1:in `inflate&#39;</span>: incorrect header check <span class="o">(</span>Zlib::DataError<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>

The binary data has now been decompressed, and being BSON data we run it through `bsondump` again and voila:

<img src="/images/ftdc-003.png">

Hopefully this helps shed some light on what FTDC data is and what it contains. In a future post we'll look into doing something useful with this treasure trove of telemetry our clusters are generating every 1 second or so.]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Troubleshooting and Fixing Invariant Failure !_featureTracker on MongoDB Startup]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/23/troubleshooting-and-fixing-invariant-failure-featuretracker/"/>
        <updated>2020-01-23T05:34:53-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/23/troubleshooting-and-fixing-invariant-failure-featuretracker</id>
        <content type="html"><![CDATA[I recently found myself troubleshooting another [MongoDB](https://www.mongodb.com/) startup issue due to potential corruption within a [WiredTiger](https://docs.mongodb.com/manual/core/wiredtiger/) file. As I have previously covered this topic (see ["Recovering a WiredTiger collection from a corrupt MongoDB installation"](/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/)), I wanted to share the diagnostic and troubleshooting journey in case it helps anyone who experiences this issue in the future.

To ensure I could troubleshoot this issue in isolation, I first collected a backup of the necessary files from the affected installation as follows:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tar -czvf metadata.tar.gz --exclude<span class="o">=</span>WiredTigerStat* WiredTiger* _mdb_catalog.wt sizeStorer.wt
</span></code></pre></td></tr></table></div></figure>

Once I had this backup I extracted it to a new location, then using [m](https://github.com/aheckmann/m) to select the versions of MongoDB to use tried to startup a standalone instance to see if I could reproduce the issue:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>mkdir -p /tmp/repro
</span><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'><span class="c"># move archive from earlier to the new directory first</span>
</span><span class='line'>tar xvf metadata.tar.gz
</span><span class='line'><span class="c"># This is the version of MongoDB reported to be crashing</span>
</span><span class='line'>m 3.4.18
</span><span class='line'>mongod --dbpath .
</span></code></pre></td></tr></table></div></figure>

Once the `mongod` started, we were able to see the failure and the process aborts (clipped log sample below).

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2020-01-23T03:58:19.828-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> db version v3.4.18
</span><span class='line'>2020-01-23T03:58:19.828-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> git version: 4410706bef6463369ea2f42399e9843903b31923
</span><span class='line'>...
</span><span class='line'>2020-01-23T03:58:20.187-0500 I -        <span class="o">[</span>initandlisten<span class="o">]</span> Invariant failure !_featureTracker src/mongo/db/storage/kv/kv_catalog.cpp 305
</span><span class='line'>2020-01-23T03:58:20.187-0500 I -        <span class="o">[</span>initandlisten<span class="o">]</span>
</span><span class='line'>
</span><span class='line'>***aborting after invariant<span class="o">()</span> failure
</span><span class='line'>
</span><span class='line'>2020-01-23T03:58:20.198-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Got signal: <span class="m">6</span> <span class="o">(</span>Aborted<span class="o">)</span>.
</span><span class='line'>...
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo15printStackTraceERSo+0x41<span class="o">)</span> <span class="o">[</span>0x55bb45c92111<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x153F329<span class="o">)</span> <span class="o">[</span>0x55bb45c91329<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x153F80D<span class="o">)</span> <span class="o">[</span>0x55bb45c9180d<span class="o">]</span>
</span><span class='line'> libpthread.so.0<span class="o">(</span>+0x12890<span class="o">)</span> <span class="o">[</span>0x7f5b7bee5890<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>gsignal+0xC7<span class="o">)</span> <span class="o">[</span>0x7f5b7bb20e97<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>abort+0x141<span class="o">)</span> <span class="o">[</span>0x7f5b7bb22801<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo17invariantOKFailedEPKcRKNS_6StatusES1_j+0x0<span class="o">)</span> <span class="o">[</span>0x55bb44f5b234<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo9KVCatalog4initEPNS_16OperationContextE+0x568<span class="o">)</span> <span class="o">[</span>0x55bb458db5e8<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo15KVStorageEngineC1EPNS_8KVEngineERKNS_22KVStorageEngineOptionsE+0x807<span class="o">)</span> <span class="o">[</span>0x55bb458e79f7<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x124DFFA<span class="o">)</span> <span class="o">[</span>0x55bb4599fffa<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>_ZN5mongo20ServiceContextMongoD29initializeGlobalStorageEngineEv+0x697<span class="o">)</span> <span class="o">[</span>0x55bb45891627<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x7F62AC<span class="o">)</span> <span class="o">[</span>0x55bb44f482ac<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>main+0x96B<span class="o">)</span> <span class="o">[</span>0x55bb44f66a6b<span class="o">]</span>
</span><span class='line'> libc.so.6<span class="o">(</span>__libc_start_main+0xE7<span class="o">)</span> <span class="o">[</span>0x7f5b7bb03b97<span class="o">]</span>
</span><span class='line'> mongod<span class="o">(</span>+0x86FFB1<span class="o">)</span> <span class="o">[</span>0x55bb44fc1fb1<span class="o">]</span>
</span><span class='line'>-----  END BACKTRACE  -----
</span><span class='line'>Aborted <span class="o">(</span>core dumped<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>

<!-- more -->

The `mongod` is failing to startup successfully due to an invariant failure during `KVCatalog::init`. We are able to determine this as the `mongod` log above tells us:

1. The MongoDB version in used (3.4.18)
2. The path to the source file where the failure occurred (file: `src/mongo/db/storage/kv/kv_catalog.cpp`, line: 305)

As MongoDB is open source, we can view the source for this release by going to https://github.com/mongodb/mongo/blob/r3.4.18/src/mongo/db/storage/kv/kv_catalog.cpp#L305, which will show us the following:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='cpp'><span class='line'><span class="k">if</span> <span class="p">(</span><span class="n">FeatureTracker</span><span class="o">::</span><span class="n">isFeatureDocument</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span> <span class="p">{</span>
</span><span class='line'>    <span class="c1">// There should be at most one version document in the catalog.</span>
</span><span class='line'>    <span class="n">invariant</span><span class="p">(</span><span class="o">!</span><span class="n">_featureTracker</span><span class="p">);</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// Initialize the feature tracker and skip over the version document because it doesn&#39;t</span>
</span><span class='line'>    <span class="c1">// correspond to a namespace entry.</span>
</span><span class='line'>    <span class="n">_featureTracker</span> <span class="o">=</span> <span class="n">FeatureTracker</span><span class="o">::</span><span class="n">get</span><span class="p">(</span><span class="n">opCtx</span><span class="p">,</span> <span class="k">this</span><span class="p">,</span> <span class="n">record</span><span class="o">-&gt;</span><span class="n">id</span><span class="p">);</span>
</span><span class='line'>    <span class="k">continue</span><span class="p">;</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>

The comment preceding the invariant<sup id="f1">[1](#fn1)</sup> indicates that there's only one feature document to be present in the catalog, but what's the catalog?

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>ls -l *catalog*
</span><span class='line'>-rw-r--r-- <span class="m">1</span> alex <span class="m">249856</span> Jan <span class="m">23</span> 03:58 _mdb_catalog.wt
</span></code></pre></td></tr></table></div></figure>

As there's only one file that contains the word "catalog" this is good a place as any to start. The `_mdb_catalog` is a WiredTiger file, so to interact with it directly (outside of MongoDB) we will need to use the [WiredTiger command line utility](http://source.wiredtiger.com/mongodb-3.4/command_line.html), also know as `wt`.

The documentation link for `mongodb-3.4` points us to WiredTiger 2.9.2, so following the [build and installation instructions](http://source.wiredtiger.com/mongodb-3.4/build-posix.html) we compile a `wt` binary with support for the snappy compressor. This is due to MongoDB's WiredTiger storage engine using snappy as the default block compressor (see ["Compression"](https://docs.mongodb.com/manual/core/wiredtiger/#compression)).

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'>git clone git://github.com/wiredtiger/wiredtiger.git
</span><span class='line'><span class="nb">cd </span>wiredtiger
</span><span class='line'>git checkout 2.9.2
</span><span class='line'>sh autogen.sh
</span><span class='line'><span class="c"># ensure you have the necessary development headers for the snappy compression</span>
</span><span class='line'><span class="c"># library before compiling</span>
</span><span class='line'>./configure --enable-snappy <span class="o">&amp;&amp;</span> make
</span></code></pre></td></tr></table></div></figure>

Once we've successfully build the `wt` utility with snappy compression we can dump our catalog to see if we can find a duplicate entry for the feature document.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">cd</span> /tmp/repro
</span><span class='line'><span class="c"># to shorten the amount of typing required, wrap the wt utility invocation in</span>
</span><span class='line'><span class="c"># a function we can call instead</span>
</span><span class='line'>WT<span class="o">()</span> <span class="o">{</span> /tmp/repro/wiredtiger/wt -v -C <span class="s2">&quot;extensions=[\&quot;/tmp/repro/wiredtiger/ext/compressors/snappy/.libs/libwiredtiger_snappy.so\&quot;]&quot;</span> <span class="nv">$@</span><span class="p">;</span> <span class="o">}</span>
</span><span class='line'><span class="c"># write the catalog dump out to a file</span>
</span><span class='line'>WT dump _mdb_catalog &gt; dump.dat
</span></code></pre></td></tr></table></div></figure>

NOTE: If you receive the following error, just re-run the command.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="o">[</span>1579773800:589375<span class="o">][</span>9348:0x7fc9a8e17140<span class="o">]</span>, txn-recover: Recovery failed: WT_RUN_RECOVERY: recovery must be run to <span class="k">continue</span>
</span><span class='line'>wt: WT_RUN_RECOVERY: recovery must be run to <span class="k">continue</span>
</span></code></pre></td></tr></table></div></figure>

This error is due to the presence of content in the `journal/` that was created when we last ran the `mongod`.

With the catalog dumped we can now search it for the feature document:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>grep isFeatureDoc dump.dat -B <span class="m">1</span> -n
</span><span class='line'>
</span><span class='line'>935-<span class="se">\c</span>2<span class="se">\e</span>5
</span><span class='line'>936:C<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>8isFeatureDoc<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>ans<span class="se">\0</span>0<span class="se">\1</span>2nonRepairable<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\1</span>2repairable<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0
</span><span class='line'>937-<span class="se">\c</span>2<span class="se">\e</span>6
</span><span class='line'>938:C<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>8isFeatureDoc<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>ans<span class="se">\0</span>0<span class="se">\1</span>2nonRepairable<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\1</span>2repairable<span class="se">\0</span>0<span class="se">\0</span>1<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0<span class="se">\0</span>0
</span></code></pre></td></tr></table></div></figure>

INTERESTING! I'm not really sure how the catalog was able to get into a state where two feature documents exist, but since we have a dump of the catalog let's try to remove one of those entries and then load the dump back into the catalog.

As the results appear to be identical, we'll just drop the first one and then try to load it back into the catalog.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="c"># remove lines 935-936 and overwrite the file</span>
</span><span class='line'>sed -i -e <span class="s1">&#39;935,936d&#39;</span> dump.dat
</span><span class='line'><span class="c"># drop the contents of the _mdb_catalog table</span>
</span><span class='line'>WT truncate _mdb_catalog
</span><span class='line'><span class="c"># reload the table from the dump file</span>
</span><span class='line'>WT load -f dump.dat
</span></code></pre></td></tr></table></div></figure>

If the table loaded successfully the output of the command should be something like `table:_mdb_catalog: 822`.

With a reloaded catalog, let's try spinning up the `mongod` again:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>2020-01-23T05:24:54.911-0500 I CONTROL  <span class="o">[</span>initandlisten<span class="o">]</span> db version v3.4.18
</span><span class='line'>...
</span><span class='line'>2020-01-23T05:24:56.247-0500 E STORAGE  <span class="o">[</span>initandlisten<span class="o">]</span> no cursor <span class="k">for</span> uri: table:SomeCollection/collection/34-1349843775853912065
</span><span class='line'>2020-01-23T05:24:56.247-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Invalid access at address: 0x58
</span><span class='line'>2020-01-23T05:24:56.259-0500 F -        <span class="o">[</span>initandlisten<span class="o">]</span> Got signal: <span class="m">11</span> <span class="o">(</span>Segmentation fault<span class="o">)</span>.
</span></code></pre></td></tr></table></div></figure>

SUCCESS! The `mongod` is still crashing as the backing files for the database don't exist, but we should now be able to take our recovered files back to our node that was previously failing.

From our recovered directory compress the following files:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>tar -czvf recovered.tar.gz --exclude<span class="o">=</span>WiredTigerStat* WiredTiger* _mdb_catalog.wt sizeStorer.wt
</span></code></pre></td></tr></table></div></figure>

Note that if the `mongod` fails to start with the recovered files you may have to clear out the `journal/` directory.

Hopefully this helps someone someday ;)

<em>If you enjoyed this post and like solving these types of problems, [MongoDB is hiring!](https://grnh.se/dcd90aac1)</em>

<hr/>
<small><b id="fn1">1</b> An invariant is a condition to test, that on failure will log the test condition, source file and line of code. [↩](#f1)</small>
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Current Date Math in MongoDB Aggregations]]></title>
        <link href="http://www.alexbevi.com/blog/2020/01/17/current-date-math-in-mongodb-aggregations/"/>
        <updated>2020-01-17T06:30:17-05:00</updated>
        <id>http://www.alexbevi.com/blog/2020/01/17/current-date-math-in-mongodb-aggregations</id>
        <content type="html"><![CDATA[A challenge that I've had in the past while working with my data in MongoDB has been how to incorporate
date math into my aggregations.

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">insertMany</span><span class="p">([</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="p">},</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">5</span><span class="p">))</span> <span class="p">},</span>
</span><span class='line'><span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">9</span><span class="p">))</span> <span class="p">}</span>
</span><span class='line'><span class="p">]);</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">find</span><span class="p">();</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975da0&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-08T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>

Given the 3 documents we've setup above, if I wanted to filter a pipeline to only [`$match`](https://docs.mongodb.com/manual/reference/operator/aggregation/match)
documents that are newer than 1 week old, I would have to resort to using Javascript:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// compare lastUpdated to a new Javascript Date object set to</span>
</span><span class='line'><span class="c1">// 7 days from the current date</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">aggregate</span><span class="p">(</span>
</span><span class='line'><span class="p">{</span> <span class="nx">$match</span><span class="o">:</span>
</span><span class='line'>  <span class="p">{</span> <span class="nx">lastUpdated</span><span class="o">:</span> <span class="p">{</span> <span class="nx">$gte</span><span class="o">:</span> <span class="k">new</span> <span class="nb">Date</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">setDate</span><span class="p">(</span><span class="k">new</span> <span class="nb">Date</span><span class="p">().</span><span class="nx">getDate</span><span class="p">()</span> <span class="o">-</span> <span class="mi">7</span><span class="p">))</span> <span class="p">}</span> <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>

Now if your pipeline is running in a non-Javascript environment, the `new Date()` call within the pipeline
would likely throw an exception.

If you're working with MongoDB 4.2 or newer though, a new [`$$NOW` aggregation variable](https://docs.mongodb.com/manual/reference/aggregation-variables/#variable.NOW
) is available that can be combined with existing pipeline operators to [`$subtract`](https://docs.mongodb.com/manual/reference/operator/aggregation/subtract/index.html
) the number of milliseconds in the number of days to filter from the current date:

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class='javascript'><span class='line'><span class="c1">// compare lastUpdated to the number of milliseconds in</span>
</span><span class='line'><span class="c1">// 7 days subtracted from the current</span>
</span><span class='line'><span class="nx">db</span><span class="p">.</span><span class="nx">foo</span><span class="p">.</span><span class="nx">aggregate</span><span class="p">(</span>
</span><span class='line'><span class="p">{</span> <span class="nx">$match</span><span class="o">:</span>
</span><span class='line'>  <span class="p">{</span> <span class="nx">$expr</span><span class="o">:</span>
</span><span class='line'>    <span class="p">{</span> <span class="nx">$let</span><span class="o">:</span>
</span><span class='line'>      <span class="p">{</span> <span class="nx">vars</span><span class="o">:</span>
</span><span class='line'>        <span class="p">{</span> <span class="nx">start</span><span class="o">:</span>
</span><span class='line'>          <span class="p">{</span> <span class="nx">$subtract</span><span class="o">:</span> <span class="p">[</span><span class="s2">&quot;$$NOW&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span> <span class="o">*</span> <span class="mi">86400000</span><span class="p">)]</span> <span class="p">}</span>
</span><span class='line'>        <span class="p">},</span>
</span><span class='line'>        <span class="k">in</span><span class="o">:</span> <span class="p">{</span> <span class="nx">$gte</span><span class="o">:</span> <span class="p">[</span><span class="s2">&quot;$lastUpdated&quot;</span><span class="p">,</span> <span class="s2">&quot;$$start&quot;</span><span class="p">]</span> <span class="p">}</span>
</span><span class='line'>      <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">});</span>
</span><span class='line'><span class="cm">/*</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9e&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-16T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">{ &quot;_id&quot; : ObjectId(&quot;5e219c6ecc99b35bb2975d9f&quot;), &quot;lastUpdated&quot; : ISODate(&quot;2020-01-12T11:37:18.522Z&quot;) }</span>
</span><span class='line'><span class="cm">*/</span>
</span></code></pre></td></tr></table></div></figure>

I hope you find this as useful as I did. With each major release of MongoDB new features and functionality
are being introduced that reduce the "hacks" or "workarounds" we've had to do in the past.

If you're looking for more MongoDB tips and tricks, head on over to Asya's [Stupid Tricks With MongoDB](http://www.kamsky.org/stupid-tricks-with-mongodb).

Let me know in the comments below if you have any questions, or if you found this useful.
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Technical Services Engineering at MongoDB]]></title>
        <link href="http://www.alexbevi.com/blog/2018/10/01/technical-services-engineering-at-mongodb/"/>
        <updated>2018-10-01T15:39:28-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/10/01/technical-services-engineering-at-mongodb</id>
        <content type="html"><![CDATA[The goal of this post is to provide a first hand account of what it means to be a *Technical Services Engineer* at [MongoDB](https://www.mongodb.com/careers/jobs/791258), as well as what the journey getting to this point has looked like for me.

### WHO AM I?

I have been working in Application Development and Software Engineering for nearly two decades. I started off writing desktop applications in QuickBASIC and Turbo Pascal, then eventually in VB6, VB.NET, C++ and C#. When it was time to shift focus to web development I started off with HTML/JS/CSS (as we all do :P), then in Flash/AS3, Flex, Python, Ruby/Rails and Node.js.

I have been writing software since I was a kid, starting with some automation tools for my mom's business. I then moved on to building tools to help me cheat at various games I was playing at the time, and eventually got more into emulator programming and reverse engineering. I guess you could say I've always loved solving problems programmatically, and especially enjoyed identifying opportunities for automation and custom tooling.

This led me down an informal DevOps track, as I was finding there was a need for optimization in the infrastructure layers that my applications were deployed to. This led me deeper into Linux internals, system administration and network operations.

While I was gaining these new skill-sets my primary focus was always on application development and delivery. Before coming to MongoDB I was working as a Development Lead / System Architect, but I found that my focus was always being drawn back to solving performance challenges at the infrastructure level.

<!-- MORE -->

### WHY MONGODB?

I started working with MongoDB on a number of "hobby" projects around 2012. At the time I really only had experience with RDBMS', but due to the unstructured nature of the data I was working with decided to give this new technology a whirl.

I fell in love with the database almost immediately, and have since carried it forward to multiple new employers, as well as contract opportunities and consulting engagements.

The low barrier to entry from a development bootstrapping perspective made it the ideal backend for proof-of-concept development through to production deployment.

As a result of this increased activity with MongoDB, I found my self doing a lot more investigation into [performance issues](/blog/2018/05/28/troubleshooting-a-mongodb-performance-issue/) and [internals](/blog/2016/02/10/recovering-a-wiredtiger-collection-from-a-corrupt-mongodb-installation/) (links are to blog posts of challenges I encountered and resolved).

### WHY TECHNICAL SERVICES?

This was initially very challenging for me, as I had pre-conceived notions as to what "technical services" actually implied. The first thoughts that popped in my head were "technical support", "client support", "call center style support", etc.

While researching this position I came across a blog post from about six years ago by a MongoDB employee who blogged about his experience as a Support Engineer (in this [two](http://blog.markofu.com/2012/07/being-support-engineer-10gen-part-1.html) [part](http://blog.markofu.com/2012/10/being-support-engineer-10gen-part-2.html) series).

I found his reasons for joining MongoDB (10gen at the time), description of what kinds of challenges the job poses on a daily basis and how there is a constant push for self improvement and continuing education to align with what I was looking for in a new opportunity.

### WHAT'S A TECHNICAL SERVICES ENGINEER ON PAPER

To answer this question, let's start off by analyzing the [job posting](https://www.mongodb.com/careers/jobs/791258) that kicked off this journey for me in the first place.

<img src="/images/why_tse/why_tse_001.png">

So they're looking for people that are able to solve problems and communicate clearly. This could be a call center gig after all ... oh wait, *experts in MongoDB related database servers, drivers, tools, services* ... hrm, maybe there's a bit more to this.

<img src="/images/why_tse/why_tse_002.png">

*Architecture, performance, recovery, security*, those are a lot more complex than what you would face in a traditional support role. What really sold me though was the *contribute to internal projects* statement, as this aligned perfectly with my desire for process improvement through custom tooling.

<img src="/images/why_tse/why_tse_003.png">

By the time I got to this point in the job posting I was already sold. MongoDB is either trying to staff their first tier support with ridiculously over-qualified employees, or Technical Services really isn't what I would have thought.

I proceeded to fill out the application, attach my resume and cover letter and crossed my fingers.

### WHAT'S A TECHNICAL SERVICES ENGINEER IN PRACTICE

After working with other TSEs for the past two months and having had an opportunity to handle some of my own cases I think I can shed a bit of light on what this role really entails.

#### HOW IS IT A SUPPORT ROLE?

A Technical Services Engineer interacts with MongoDB's clients via a support queue. This allows incoming "cases" to be prioritized and categorized to allow engineers to quickly identify what form of subject matter expertise may be required (ex: `Indexing`, `Replication`, `Sharding`, `Performance`, `Networking`, etc).

As a TSE you're responsible for claiming cases from a queue and providing feedback in a timely fashion that is clear, concise and technically accurate.

#### HOW IS IT AN ENGINEERING ROLE?

Here's the juicy part of this job. Although replying to client requests is the "deliverable" for a TSE, how you go about reproducing their issues requires a very deep understanding of MongoDB internals, software engineering, network engineering, infrastructure architecture and technical troubleshooting.

Depending on the type of issue, a reproduction is likely in store. These involve recreating the environment (locally or in the cloud) to either benchmark or replicate the identified client challenge. There is a vast library of tools available to TSEs for these types of tasks, but on some occasions the right tool for the job may not exist.

In these cases, you have an opportunity to write your own scripts or tools to parse logs, measure performance, record telemetry or verify a hypothesis. Although MongoDB doesn't require TSEs to have any programming experience, for those like me that come from product engineering it's refreshing to know there's still an opportunity to scratch the development itch.

With each case you learn more about the inner working of the database, the tools, the drivers and OS level performance.

### CONCLUSION?

I'm leaving the closing section here as a question, as the TSE role continues to be redefined and refined as new MongoDB products come on board and new challenges present themselves.

What will likely remain constant though is the need for new engineers to have the following characteristics:

* a passion for continuing technical education
* a willingness to step outside their comfort zone
* an interest in software engineering
* an interest in network operations

I encourage you to check out MongoDB's [available jobs](https://grnh.se/dcd90aac1) if what I've described here interests you (I swear HR is not putting me up to this ...) as we could use more engineers like you in our ranks :)

Feel free to leave a comment below or shoot me an email at [alex@alexbevi.com](mailto:alex@alexbevi.com) if you have any questions.
]]></content>
    </entry>
    
    <entry>
        <title type="html"><![CDATA[Hello MongoDB]]></title>
        <link href="http://www.alexbevi.com/blog/2018/08/14/hello-mongodb/"/>
        <updated>2018-08-14T15:31:04-04:00</updated>
        <id>http://www.alexbevi.com/blog/2018/08/14/hello-mongodb</id>
        <content type="html"><![CDATA[As of August 13th, I am no longer a System Architect at DAC Group. I have a public post on [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:6432589236368601088/) that got some good traction, but to summarize it was time to move on.

I've been a software engineer in some capacity or another for nearly 20 years now. The position I've taken is as a *Technical Services Engineer*, which is more of a support role than an active development role.

The decision to make this move wasn't make lightly. I've been working hands on with code or overseeing a team of developers on a day to day basis for most of my professional career. As such, I was also involved with software engineering, and this was no different in my role as a *System Architect*.

In that role, I was still committing code on a nearly daily basis. If not, I was performing code review, or working on a design for a new system or solution. I would consider this all to still be "hands on", though I had found myself mired in DevOps work a lot more than I would have liked (there were not sufficient Linux Sysadmins available to assist with the type of server operations oversight that was required).

The role at MongoDB isn't a traditional "Tech Support" type of role, as it requires a strong knowledge of networking, databases, system design, programming and client services. I've been a fan of the MongoDB server for over 8 years now, and have brought it along with me to several new consulting opportunities as well as the full time jobs I've help. I believe very strongly in the quality of this product, as well as the peripheral products that they've developed.

I think the time has come for a new adventure. This is the first step towards a new career journey with a new company, as opposed to an incremental move upwards within the same professional space.]]></content>
    </entry>
    
</feed>
